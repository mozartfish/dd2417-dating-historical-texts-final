{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8067c989",
   "metadata": {},
   "source": [
    "# DD2417 Final Project - Dating Historical Texts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea74981f",
   "metadata": {},
   "source": [
    "## Libraries + Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5995f27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# seed all experiments and setup\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f081e4ec",
   "metadata": {},
   "source": [
    "## Data - Setup and Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459303ab",
   "metadata": {},
   "source": [
    "### Path Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7593bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "raw_dataset_path = \"./Datasets/raw_data\"\n",
    "\n",
    "# raw split\n",
    "raw_train_split_path = \"./Datasets/raw_train_split\"\n",
    "raw_test_split_path = \"./Datasets/raw_test_split\"\n",
    "\n",
    "# clean split\n",
    "clean_train_split_path = \"./Datasets/clean_train_split\"\n",
    "clean_test_split_path = \"./Datasets/clean_test_split\"\n",
    "\n",
    "# model\n",
    "model_dataset_path = \"./Datasets/model_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59447748",
   "metadata": {},
   "source": [
    "#### Cleanup Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b068f3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(train_path, test_path):\n",
    "    print(f\"clean up train path - {train_path}\")\n",
    "    train_dir = os.listdir(train_path)\n",
    "    train_dir.sort()\n",
    "    for dir in train_dir:\n",
    "        decade_path = os.path.join(train_path, dir)\n",
    "        if os.path.isdir(decade_path):\n",
    "            text_files = os.listdir(decade_path)\n",
    "            text_files.sort()\n",
    "            for file in text_files:\n",
    "                if file.endswith(\".txt\"):\n",
    "                    file_path = os.path.join(decade_path, file)\n",
    "                    os.remove(file_path)\n",
    "                    print(f\"succesfully remove {file}\")\n",
    "            os.rmdir(decade_path)\n",
    "            print(f\"succesfully removed directory {dir}\")\n",
    "            print()\n",
    "\n",
    "    print(f\"clean up test path - {test_path}\")\n",
    "    test_dir = os.listdir(test_path)\n",
    "    test_dir.sort()\n",
    "    for dir in test_dir:\n",
    "        decade_path = os.path.join(test_path, dir)\n",
    "        if os.path.isdir(decade_path):\n",
    "            text_files = os.listdir(decade_path)\n",
    "            text_files.sort()\n",
    "            for file in text_files:\n",
    "                if file.endswith(\".txt\"):\n",
    "                    file_path = os.path.join(decade_path, file)\n",
    "                    os.remove(file_path)\n",
    "                    print(f\"succesfully remove {file}\")\n",
    "            os.rmdir(decade_path)\n",
    "            print(f\"succesfully removed directory {dir}\")\n",
    "            print()\n",
    "\n",
    "    os.rmdir(train_path)\n",
    "    print(f\"succesfully removed {train_path}\")\n",
    "    os.rmdir(test_path)\n",
    "    print(f\"succesfully removed {test_path}\")\n",
    "    print(f\"succesfully cleaned up training and test files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e57f4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_model_data(model_dataset_path):\n",
    "    print(f\"clean up model path - {model_dataset_path}\")\n",
    "    files = os.listdir(model_dataset_path)\n",
    "\n",
    "    # Remove each file\n",
    "    for file in files:\n",
    "        file_path = os.path.join(model_dataset_path, file)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "            print(f\"successfully removed {file}\")\n",
    "    os.rmdir(model_dataset_path)\n",
    "    print(f\"successfully removed {model_dataset_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e278e6f0",
   "metadata": {},
   "source": [
    "#### Create data directories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b02b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean up train path - ./Datasets/raw_train_split\n",
      "succesfully remove book_03.txt\n",
      "succesfully remove book_04.txt\n",
      "succesfully remove book_05.txt\n",
      "succesfully remove book_06.txt\n",
      "succesfully remove book_07.txt\n",
      "succesfully remove book_08.txt\n",
      "succesfully remove book_09.txt\n",
      "succesfully remove book_10.txt\n",
      "succesfully remove book_12.txt\n",
      "succesfully removed directory 1770\n",
      "\n",
      "succesfully remove book_03.txt\n",
      "succesfully remove book_04.txt\n",
      "succesfully remove book_05.txt\n",
      "succesfully remove book_06.txt\n",
      "succesfully remove book_07.txt\n",
      "succesfully remove book_08.txt\n",
      "succesfully remove book_09.txt\n",
      "succesfully remove book_10.txt\n",
      "succesfully remove book_11.txt\n",
      "succesfully removed directory 1780\n",
      "\n",
      "succesfully remove book_01.txt\n",
      "succesfully remove book_02.txt\n",
      "succesfully remove book_03.txt\n",
      "succesfully remove book_06.txt\n",
      "succesfully remove book_07.txt\n",
      "succesfully remove book_09.txt\n",
      "succesfully remove book_10.txt\n",
      "succesfully remove book_11.txt\n",
      "succesfully removed directory 1790\n",
      "\n",
      "succesfully remove book_01.txt\n",
      "succesfully remove book_02.txt\n",
      "succesfully remove book_03.txt\n",
      "succesfully remove book_05.txt\n",
      "succesfully remove book_07.txt\n",
      "succesfully remove book_08.txt\n",
      "succesfully remove book_09.txt\n",
      "succesfully remove book_10.txt\n",
      "succesfully removed directory 1800\n",
      "\n",
      "succesfully remove book_02.txt\n",
      "succesfully remove book_03.txt\n",
      "succesfully remove book_04.txt\n",
      "succesfully remove book_05.txt\n",
      "succesfully remove book_06.txt\n",
      "succesfully remove book_07.txt\n",
      "succesfully remove book_08.txt\n",
      "succesfully remove book_09.txt\n",
      "succesfully remove book_10.txt\n",
      "succesfully remove book_11.txt\n",
      "succesfully remove book_14.txt\n",
      "succesfully remove book_15.txt\n",
      "succesfully removed directory 1810\n",
      "\n",
      "succesfully remove book_03.txt\n",
      "succesfully remove book_04.txt\n",
      "succesfully remove book_05.txt\n",
      "succesfully remove book_06.txt\n",
      "succesfully remove book_07.txt\n",
      "succesfully remove book_08.txt\n",
      "succesfully remove book_09.txt\n",
      "succesfully remove book_10.txt\n",
      "succesfully remove book_11.txt\n",
      "succesfully remove book_13.txt\n",
      "succesfully remove book_14.txt\n",
      "succesfully removed directory 1820\n",
      "\n",
      "succesfully remove book_01.txt\n",
      "succesfully remove book_02.txt\n",
      "succesfully remove book_04.txt\n",
      "succesfully remove book_05.txt\n",
      "succesfully remove book_07.txt\n",
      "succesfully remove book_08.txt\n",
      "succesfully remove book_09.txt\n",
      "succesfully remove book_10.txt\n",
      "succesfully remove book_12.txt\n",
      "succesfully removed directory 1830\n",
      "\n",
      "succesfully remove book_01.txt\n",
      "succesfully remove book_02.txt\n",
      "succesfully remove book_03.txt\n",
      "succesfully remove book_05.txt\n",
      "succesfully remove book_06.txt\n",
      "succesfully remove book_07.txt\n",
      "succesfully remove book_08.txt\n",
      "succesfully remove book_10.txt\n",
      "succesfully remove book_11.txt\n",
      "succesfully remove book_13.txt\n",
      "succesfully removed directory 1840\n",
      "\n",
      "succesfully remove book_02.txt\n",
      "succesfully remove book_03.txt\n",
      "succesfully remove book_05.txt\n",
      "succesfully remove book_06.txt\n",
      "succesfully remove book_07.txt\n",
      "succesfully remove book_08.txt\n",
      "succesfully remove book_09.txt\n",
      "succesfully remove book_10.txt\n",
      "succesfully remove book_11.txt\n",
      "succesfully remove book_12.txt\n",
      "succesfully removed directory 1850\n",
      "\n",
      "succesfully remove book_01.txt\n",
      "succesfully remove book_02.txt\n",
      "succesfully remove book_03.txt\n",
      "succesfully remove book_04.txt\n",
      "succesfully remove book_05.txt\n",
      "succesfully remove book_06.txt\n",
      "succesfully remove book_09.txt\n",
      "succesfully remove book_10.txt\n",
      "succesfully remove book_12.txt\n",
      "succesfully removed directory 1860\n",
      "\n",
      "succesfully remove book_01.txt\n",
      "succesfully remove book_02.txt\n",
      "succesfully remove book_03.txt\n",
      "succesfully remove book_04.txt\n",
      "succesfully remove book_05.txt\n",
      "succesfully remove book_08.txt\n",
      "succesfully remove book_09.txt\n",
      "succesfully remove book_11.txt\n",
      "succesfully remove book_12.txt\n",
      "succesfully removed directory 1870\n",
      "\n",
      "succesfully remove book_01.txt\n",
      "succesfully remove book_02.txt\n",
      "succesfully remove book_04.txt\n",
      "succesfully remove book_05.txt\n",
      "succesfully remove book_06.txt\n",
      "succesfully remove book_08.txt\n",
      "succesfully remove book_09.txt\n",
      "succesfully remove book_10.txt\n",
      "succesfully remove book_12.txt\n",
      "succesfully removed directory 1880\n",
      "\n",
      "succesfully remove book_01.txt\n",
      "succesfully remove book_03.txt\n",
      "succesfully remove book_04.txt\n",
      "succesfully remove book_05.txt\n",
      "succesfully remove book_06.txt\n",
      "succesfully remove book_07.txt\n",
      "succesfully remove book_08.txt\n",
      "succesfully remove book_10.txt\n",
      "succesfully remove book_12.txt\n",
      "succesfully removed directory 1890\n",
      "\n",
      "clean up test path - ./Datasets/raw_test_split\n",
      "succesfully remove book_01.txt\n",
      "succesfully remove book_02.txt\n",
      "succesfully remove book_11.txt\n",
      "succesfully removed directory 1770\n",
      "\n",
      "succesfully remove book_01.txt\n",
      "succesfully remove book_02.txt\n",
      "succesfully remove book_12.txt\n",
      "succesfully removed directory 1780\n",
      "\n",
      "succesfully remove book_04.txt\n",
      "succesfully remove book_05.txt\n",
      "succesfully remove book_08.txt\n",
      "succesfully removed directory 1790\n",
      "\n",
      "succesfully remove book_04.txt\n",
      "succesfully remove book_06.txt\n",
      "succesfully removed directory 1800\n",
      "\n",
      "succesfully remove book_01.txt\n",
      "succesfully remove book_12.txt\n",
      "succesfully remove book_13.txt\n",
      "succesfully removed directory 1810\n",
      "\n",
      "succesfully remove book_01.txt\n",
      "succesfully remove book_02.txt\n",
      "succesfully remove book_12.txt\n",
      "succesfully removed directory 1820\n",
      "\n",
      "succesfully remove book_03.txt\n",
      "succesfully remove book_06.txt\n",
      "succesfully remove book_11.txt\n",
      "succesfully removed directory 1830\n",
      "\n",
      "succesfully remove book_04.txt\n",
      "succesfully remove book_09.txt\n",
      "succesfully remove book_12.txt\n",
      "succesfully removed directory 1840\n",
      "\n",
      "succesfully remove book_01.txt\n",
      "succesfully remove book_04.txt\n",
      "succesfully remove book_13.txt\n",
      "succesfully removed directory 1850\n",
      "\n",
      "succesfully remove book_07.txt\n",
      "succesfully remove book_08.txt\n",
      "succesfully remove book_11.txt\n",
      "succesfully removed directory 1860\n",
      "\n",
      "succesfully remove book_06.txt\n",
      "succesfully remove book_07.txt\n",
      "succesfully remove book_10.txt\n",
      "succesfully removed directory 1870\n",
      "\n",
      "succesfully remove book_03.txt\n",
      "succesfully remove book_07.txt\n",
      "succesfully remove book_11.txt\n",
      "succesfully removed directory 1880\n",
      "\n",
      "succesfully remove book_02.txt\n",
      "succesfully remove book_09.txt\n",
      "succesfully remove book_11.txt\n",
      "succesfully removed directory 1890\n",
      "\n",
      "succesfully removed ./Datasets/raw_train_split\n",
      "succesfully removed ./Datasets/raw_test_split\n",
      "succesfully cleaned up training and test files\n",
      "create raw train split directory\n",
      "create raw test split directory\n",
      "create model data directory \n"
     ]
    }
   ],
   "source": [
    "# raw split\n",
    "if os.path.exists(raw_train_split_path) and os.path.exists(raw_test_split_path):\n",
    "    cleanup(raw_train_split_path, raw_test_split_path)\n",
    "\n",
    "os.makedirs(raw_train_split_path)\n",
    "print(f\"create raw train split directory\")\n",
    "\n",
    "os.makedirs(raw_test_split_path)\n",
    "print(f\"create raw test split directory\")\n",
    "\n",
    "os.makedirs(model_dataset_path)\n",
    "print(f\"create model data directory \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6409dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean up train path - ./Datasets/clean_train_split\n",
      "succesfully remove book_03.txt\n",
      "succesfully remove book_04.txt\n",
      "succesfully remove book_05.txt\n",
      "succesfully remove book_06.txt\n",
      "succesfully remove book_07.txt\n",
      "succesfully remove book_08.txt\n",
      "succesfully remove book_09.txt\n",
      "succesfully remove book_10.txt\n",
      "succesfully remove book_12.txt\n",
      "succesfully removed directory 1770\n",
      "\n",
      "succesfully remove book_03.txt\n",
      "succesfully remove book_04.txt\n",
      "succesfully remove book_05.txt\n",
      "succesfully remove book_06.txt\n",
      "succesfully remove book_07.txt\n",
      "succesfully remove book_08.txt\n",
      "succesfully remove book_09.txt\n",
      "succesfully remove book_10.txt\n",
      "succesfully remove book_11.txt\n",
      "succesfully removed directory 1780\n",
      "\n",
      "succesfully remove book_01.txt\n",
      "succesfully remove book_02.txt\n",
      "succesfully remove book_03.txt\n",
      "succesfully remove book_06.txt\n",
      "succesfully remove book_07.txt\n",
      "succesfully remove book_09.txt\n",
      "succesfully remove book_10.txt\n",
      "succesfully remove book_11.txt\n",
      "succesfully removed directory 1790\n",
      "\n",
      "succesfully remove book_01.txt\n",
      "succesfully remove book_02.txt\n",
      "succesfully remove book_03.txt\n",
      "succesfully remove book_05.txt\n",
      "succesfully remove book_07.txt\n",
      "succesfully remove book_08.txt\n",
      "succesfully remove book_09.txt\n",
      "succesfully remove book_10.txt\n",
      "succesfully removed directory 1800\n",
      "\n",
      "succesfully remove book_02.txt\n",
      "succesfully remove book_03.txt\n",
      "succesfully remove book_04.txt\n",
      "succesfully remove book_05.txt\n",
      "succesfully remove book_06.txt\n",
      "succesfully remove book_07.txt\n",
      "succesfully remove book_08.txt\n",
      "succesfully remove book_09.txt\n",
      "succesfully remove book_10.txt\n",
      "succesfully remove book_11.txt\n",
      "succesfully remove book_14.txt\n",
      "succesfully remove book_15.txt\n",
      "succesfully removed directory 1810\n",
      "\n",
      "succesfully remove book_03.txt\n",
      "succesfully remove book_04.txt\n",
      "succesfully remove book_05.txt\n",
      "succesfully remove book_06.txt\n",
      "succesfully remove book_07.txt\n",
      "succesfully remove book_08.txt\n",
      "succesfully remove book_09.txt\n",
      "succesfully remove book_10.txt\n",
      "succesfully remove book_11.txt\n",
      "succesfully remove book_13.txt\n",
      "succesfully remove book_14.txt\n",
      "succesfully removed directory 1820\n",
      "\n",
      "succesfully remove book_01.txt\n",
      "succesfully remove book_02.txt\n",
      "succesfully remove book_04.txt\n",
      "succesfully remove book_05.txt\n",
      "succesfully remove book_07.txt\n",
      "succesfully remove book_08.txt\n",
      "succesfully remove book_09.txt\n",
      "succesfully remove book_10.txt\n",
      "succesfully remove book_12.txt\n",
      "succesfully removed directory 1830\n",
      "\n",
      "succesfully remove book_01.txt\n",
      "succesfully remove book_02.txt\n",
      "succesfully remove book_03.txt\n",
      "succesfully remove book_05.txt\n",
      "succesfully remove book_06.txt\n",
      "succesfully remove book_07.txt\n",
      "succesfully remove book_08.txt\n",
      "succesfully remove book_10.txt\n",
      "succesfully remove book_11.txt\n",
      "succesfully remove book_13.txt\n",
      "succesfully removed directory 1840\n",
      "\n",
      "succesfully remove book_02.txt\n",
      "succesfully remove book_03.txt\n",
      "succesfully remove book_05.txt\n",
      "succesfully remove book_06.txt\n",
      "succesfully remove book_07.txt\n",
      "succesfully remove book_08.txt\n",
      "succesfully remove book_09.txt\n",
      "succesfully remove book_10.txt\n",
      "succesfully remove book_11.txt\n",
      "succesfully remove book_12.txt\n",
      "succesfully removed directory 1850\n",
      "\n",
      "succesfully remove book_01.txt\n",
      "succesfully remove book_02.txt\n",
      "succesfully remove book_03.txt\n",
      "succesfully remove book_04.txt\n",
      "succesfully remove book_05.txt\n",
      "succesfully remove book_06.txt\n",
      "succesfully remove book_09.txt\n",
      "succesfully remove book_10.txt\n",
      "succesfully remove book_12.txt\n",
      "succesfully removed directory 1860\n",
      "\n",
      "succesfully remove book_01.txt\n",
      "succesfully remove book_02.txt\n",
      "succesfully remove book_03.txt\n",
      "succesfully remove book_04.txt\n",
      "succesfully remove book_05.txt\n",
      "succesfully remove book_08.txt\n",
      "succesfully remove book_09.txt\n",
      "succesfully remove book_11.txt\n",
      "succesfully remove book_12.txt\n",
      "succesfully removed directory 1870\n",
      "\n",
      "succesfully remove book_01.txt\n",
      "succesfully remove book_02.txt\n",
      "succesfully remove book_04.txt\n",
      "succesfully remove book_05.txt\n",
      "succesfully remove book_06.txt\n",
      "succesfully remove book_08.txt\n",
      "succesfully remove book_09.txt\n",
      "succesfully remove book_10.txt\n",
      "succesfully remove book_12.txt\n",
      "succesfully removed directory 1880\n",
      "\n",
      "succesfully remove book_01.txt\n",
      "succesfully remove book_03.txt\n",
      "succesfully remove book_04.txt\n",
      "succesfully remove book_05.txt\n",
      "succesfully remove book_06.txt\n",
      "succesfully remove book_07.txt\n",
      "succesfully remove book_08.txt\n",
      "succesfully remove book_10.txt\n",
      "succesfully remove book_12.txt\n",
      "succesfully removed directory 1890\n",
      "\n",
      "clean up test path - ./Datasets/clean_test_split\n",
      "succesfully remove book_01.txt\n",
      "succesfully remove book_02.txt\n",
      "succesfully remove book_11.txt\n",
      "succesfully removed directory 1770\n",
      "\n",
      "succesfully remove book_01.txt\n",
      "succesfully remove book_02.txt\n",
      "succesfully remove book_12.txt\n",
      "succesfully removed directory 1780\n",
      "\n",
      "succesfully remove book_04.txt\n",
      "succesfully remove book_05.txt\n",
      "succesfully remove book_08.txt\n",
      "succesfully removed directory 1790\n",
      "\n",
      "succesfully remove book_04.txt\n",
      "succesfully remove book_06.txt\n",
      "succesfully removed directory 1800\n",
      "\n",
      "succesfully remove book_01.txt\n",
      "succesfully remove book_12.txt\n",
      "succesfully remove book_13.txt\n",
      "succesfully removed directory 1810\n",
      "\n",
      "succesfully remove book_01.txt\n",
      "succesfully remove book_02.txt\n",
      "succesfully remove book_12.txt\n",
      "succesfully removed directory 1820\n",
      "\n",
      "succesfully remove book_03.txt\n",
      "succesfully remove book_06.txt\n",
      "succesfully remove book_11.txt\n",
      "succesfully removed directory 1830\n",
      "\n",
      "succesfully remove book_04.txt\n",
      "succesfully remove book_09.txt\n",
      "succesfully remove book_12.txt\n",
      "succesfully removed directory 1840\n",
      "\n",
      "succesfully remove book_01.txt\n",
      "succesfully remove book_04.txt\n",
      "succesfully remove book_13.txt\n",
      "succesfully removed directory 1850\n",
      "\n",
      "succesfully remove book_07.txt\n",
      "succesfully remove book_08.txt\n",
      "succesfully remove book_11.txt\n",
      "succesfully removed directory 1860\n",
      "\n",
      "succesfully remove book_06.txt\n",
      "succesfully remove book_07.txt\n",
      "succesfully remove book_10.txt\n",
      "succesfully removed directory 1870\n",
      "\n",
      "succesfully remove book_03.txt\n",
      "succesfully remove book_07.txt\n",
      "succesfully remove book_11.txt\n",
      "succesfully removed directory 1880\n",
      "\n",
      "succesfully remove book_02.txt\n",
      "succesfully remove book_09.txt\n",
      "succesfully remove book_11.txt\n",
      "succesfully removed directory 1890\n",
      "\n",
      "succesfully removed ./Datasets/clean_train_split\n",
      "succesfully removed ./Datasets/clean_test_split\n",
      "succesfully cleaned up training and test files\n",
      "create clean train split directory\n",
      "create clean test split directory\n"
     ]
    }
   ],
   "source": [
    "# clean split\n",
    "if os.path.exists(clean_train_split_path) and os.path.exists(clean_test_split_path):\n",
    "    cleanup(clean_train_split_path, clean_test_split_path)\n",
    "\n",
    "os.makedirs(clean_train_split_path)\n",
    "print(f\"create clean train split directory\")\n",
    "os.makedirs(clean_test_split_path)\n",
    "print(f\"create clean test split directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d4fea9",
   "metadata": {},
   "source": [
    "### Book Data Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c982361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count the number of books in each decade directory in the raw data\n",
      "1770: 12 books\n",
      "1780: 12 books\n",
      "1790: 11 books\n",
      "1800: 10 books\n",
      "1810: 15 books\n",
      "1820: 14 books\n",
      "1830: 12 books\n",
      "1840: 13 books\n",
      "1850: 13 books\n",
      "1860: 12 books\n",
      "1870: 12 books\n",
      "1880: 12 books\n",
      "1890: 12 books\n",
      "total number of books for project: 160\n"
     ]
    }
   ],
   "source": [
    "# count all the data files in the raw data file\n",
    "print(f\"count the number of books in each decade directory in the raw data\")\n",
    "total_books = 0\n",
    "for decade in range(1700, 1900, 10):\n",
    "    decade_path = f\"{raw_dataset_path}/{decade}\"\n",
    "    if os.path.exists(decade_path):\n",
    "        text_files = [f for f in os.listdir(decade_path) if f.endswith(\".txt\")]\n",
    "        print(f\"{decade}: {len(text_files)} books\")\n",
    "        total_books += len(text_files)\n",
    "print(f\"total number of books for project: {total_books}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732386ba",
   "metadata": {},
   "source": [
    "#### Get the Titles of Books in the Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "80a9caf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['An Inquiry into the Nature and Causes of the Wealth of Nations', 'She Stoops to Conquer; Or, The Mistakes of a Night: A Comedy', 'The School for Scandal', 'The Expedition of Humphry Clinker', \"Evelina, Or, the History of a Young Lady's Entrance into the World\", 'The Rivals: A Comedy', 'The Life and Opinions of Tristram Shandy, Gentleman', 'The History of the Decline and Fall of the Roman Empire', 'A Journey to the Western Islands of Scotland', 'Common Sense', 'The Man of Feeling', 'The Deserted Village']\n"
     ]
    }
   ],
   "source": [
    "# get all the titles of the books\n",
    "def get_book_titles(dataset_path):\n",
    "    book_titles = {}\n",
    "    for year in range(1770, 1900, 10):\n",
    "        decade_path = f\"{dataset_path}/{year}\"\n",
    "        book_titles[year] = []\n",
    "\n",
    "        # print(f\"decade: {year}\")\n",
    "        text_files = sorted([f for f in os.listdir(decade_path) if f.endswith(\".txt\")])\n",
    "        for filename in text_files:\n",
    "            file_path = os.path.join(decade_path, filename)\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                text = f.read()\n",
    "            title_match = re.search(r\"^Title:\\s*(.+)$\", text, re.MULTILINE)\n",
    "            book_title = title_match.group(1).strip()\n",
    "            # print(f\"book_title: {book_title}\")\n",
    "            # filename_to_title[filename] = book_title\n",
    "            book_titles[year].append(book_title)\n",
    "        # print(f\"number of titles in decade: {year} -> {len(book_titles[year])}\")\n",
    "        print()\n",
    "    return book_titles\n",
    "\n",
    "\n",
    "book_titles = get_book_titles(raw_dataset_path)\n",
    "print(f\"{book_titles[1770]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0bcc7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "total number of books processed: 160\n",
      "The length of result after calling raw dataset info: 160\n"
     ]
    }
   ],
   "source": [
    "def raw_dataset_info(dataset_path):\n",
    "    years = [i for i in range(1770, 1900, 10)]\n",
    "    book_titles = get_book_titles(dataset_path)\n",
    "\n",
    "    book_data = []\n",
    "    for decade in years:\n",
    "        decade_path = f\"{dataset_path}/{decade}\"\n",
    "        if os.path.exists(decade_path):\n",
    "            text_files = sorted(\n",
    "                [f for f in os.listdir(decade_path) if f.endswith(\".txt\")]\n",
    "            )\n",
    "            for index, filename in enumerate(text_files):\n",
    "                if decade in book_titles and index < len(book_titles[decade]):\n",
    "                    book_title = book_titles[decade][index]\n",
    "                else:\n",
    "                    book_title = f\"unknown_book_{index + 1}\"\n",
    "                book_info = {\n",
    "                    \"decade\": decade,\n",
    "                    \"filename\": filename,\n",
    "                    \"book_title\": book_title,\n",
    "                    \"filepath\": os.path.join(decade_path, filename),\n",
    "                    \"book_id\": f\"{decade}_{book_title[:20].replace(' ', '_')}\",\n",
    "                }\n",
    "                book_data.append(book_info)\n",
    "    print(f\"total number of books processed: {len(book_data)}\")\n",
    "    return book_data\n",
    "\n",
    "\n",
    "raw_data_info = raw_dataset_info(raw_dataset_path)\n",
    "print(f\"The length of result after calling raw dataset info: {len(raw_data_info)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69383a3",
   "metadata": {},
   "source": [
    "## Data Split - Stratified Split of Books - Training Books, Testing Books\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b8b337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "total number of books processed: 160\n",
      "TRAIN BOOKS: 122\n",
      "TEST BOOKS: 38\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This functions performs a stratified split of the data. Since we have a limited number of books, we took 80% of the total books to be used \n",
    "for training and then held out 20% of the books for testing. Our original number of books was 160 - 122 were used for Training/Validation, \n",
    "38 were used for testing\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def create_stratified_split(book_data, train_split=0.8):\n",
    "    train_books, test_books = [], []\n",
    "    books_by_decade = {}\n",
    "\n",
    "    books_by_decade = {}\n",
    "    for book in book_data:\n",
    "        decade = book[\"decade\"]\n",
    "        if decade not in books_by_decade:\n",
    "            books_by_decade[decade] = []\n",
    "        books_by_decade[decade].append(book)\n",
    "\n",
    "    # debug check\n",
    "    # for decade, books in books_by_decade.items():\n",
    "    #     print(f\"decade: {decade}, number of books: {len(books)}\")\n",
    "\n",
    "    for decade, books in sorted(books_by_decade.items()):\n",
    "        shuffled_books = books.copy()\n",
    "        random.shuffle(shuffled_books)\n",
    "\n",
    "        total_books = len(books)\n",
    "        train_size = max(1, int(total_books * train_split))\n",
    "        test_size = total_books - train_size\n",
    "        decade_train = shuffled_books[:train_size]\n",
    "        decade_test = shuffled_books[train_size:]\n",
    "\n",
    "        train_books.extend(decade_train)\n",
    "        test_books.extend(decade_test)\n",
    "\n",
    "    print(f\"TRAIN BOOKS: {len(train_books)}\")\n",
    "    print(f\"TEST BOOKS: {len(test_books)}\")\n",
    "\n",
    "    return train_books, test_books\n",
    "\n",
    "\n",
    "raw_book_data = raw_dataset_info(raw_dataset_path)\n",
    "raw_train, raw_test = create_stratified_split(raw_book_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef616d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_stratified_split(dataset, file_path):\n",
    "    for i, book in enumerate(dataset):\n",
    "        print(f\"book: {i + 1}\")\n",
    "        # decade\n",
    "        book_decade = str(book[\"decade\"])\n",
    "        # title\n",
    "        book_title = book[\"book_title\"]\n",
    "        # filename\n",
    "        book_filename = book[\"filename\"]\n",
    "        # path\n",
    "        book_path = book[\"filepath\"]\n",
    "\n",
    "        print(f\"read book <- {book_path}\")\n",
    "        with open(book_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            raw_book = f.read()\n",
    "\n",
    "        decade_path = os.path.join(file_path, book_decade)\n",
    "        if not os.path.isdir(decade_path):\n",
    "            os.makedirs(decade_path)\n",
    "        out_file = decade_path + \"/\" + book_filename\n",
    "        book[\"file_path\"] = out_file\n",
    "        print(f\"new book filepath: {book_path}\")\n",
    "        print(f\"write book -> {out_file}\")\n",
    "        with open(out_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(raw_book)\n",
    "        print(f\"wrote book successfully!!!\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "87d1fb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book: 1\n",
      "read book <- ./Datasets/raw_data/1770/book_08.txt\n",
      "new book filepath: ./Datasets/raw_data/1770/book_08.txt\n",
      "write book -> ./Datasets/raw_train_split/1770/book_08.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 2\n",
      "read book <- ./Datasets/raw_data/1770/book_06.txt\n",
      "new book filepath: ./Datasets/raw_data/1770/book_06.txt\n",
      "write book -> ./Datasets/raw_train_split/1770/book_06.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 3\n",
      "read book <- ./Datasets/raw_data/1770/book_03.txt\n",
      "new book filepath: ./Datasets/raw_data/1770/book_03.txt\n",
      "write book -> ./Datasets/raw_train_split/1770/book_03.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 4\n",
      "read book <- ./Datasets/raw_data/1770/book_09.txt\n",
      "new book filepath: ./Datasets/raw_data/1770/book_09.txt\n",
      "write book -> ./Datasets/raw_train_split/1770/book_09.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 5\n",
      "read book <- ./Datasets/raw_data/1770/book_10.txt\n",
      "new book filepath: ./Datasets/raw_data/1770/book_10.txt\n",
      "write book -> ./Datasets/raw_train_split/1770/book_10.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 6\n",
      "read book <- ./Datasets/raw_data/1770/book_07.txt\n",
      "new book filepath: ./Datasets/raw_data/1770/book_07.txt\n",
      "write book -> ./Datasets/raw_train_split/1770/book_07.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 7\n",
      "read book <- ./Datasets/raw_data/1770/book_12.txt\n",
      "new book filepath: ./Datasets/raw_data/1770/book_12.txt\n",
      "write book -> ./Datasets/raw_train_split/1770/book_12.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 8\n",
      "read book <- ./Datasets/raw_data/1770/book_04.txt\n",
      "new book filepath: ./Datasets/raw_data/1770/book_04.txt\n",
      "write book -> ./Datasets/raw_train_split/1770/book_04.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 9\n",
      "read book <- ./Datasets/raw_data/1770/book_05.txt\n",
      "new book filepath: ./Datasets/raw_data/1770/book_05.txt\n",
      "write book -> ./Datasets/raw_train_split/1770/book_05.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 10\n",
      "read book <- ./Datasets/raw_data/1780/book_06.txt\n",
      "new book filepath: ./Datasets/raw_data/1780/book_06.txt\n",
      "write book -> ./Datasets/raw_train_split/1780/book_06.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 11\n",
      "read book <- ./Datasets/raw_data/1780/book_08.txt\n",
      "new book filepath: ./Datasets/raw_data/1780/book_08.txt\n",
      "write book -> ./Datasets/raw_train_split/1780/book_08.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 12\n",
      "read book <- ./Datasets/raw_data/1780/book_03.txt\n",
      "new book filepath: ./Datasets/raw_data/1780/book_03.txt\n",
      "write book -> ./Datasets/raw_train_split/1780/book_03.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 13\n",
      "read book <- ./Datasets/raw_data/1780/book_10.txt\n",
      "new book filepath: ./Datasets/raw_data/1780/book_10.txt\n",
      "write book -> ./Datasets/raw_train_split/1780/book_10.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 14\n",
      "read book <- ./Datasets/raw_data/1780/book_11.txt\n",
      "new book filepath: ./Datasets/raw_data/1780/book_11.txt\n",
      "write book -> ./Datasets/raw_train_split/1780/book_11.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 15\n",
      "read book <- ./Datasets/raw_data/1780/book_07.txt\n",
      "new book filepath: ./Datasets/raw_data/1780/book_07.txt\n",
      "write book -> ./Datasets/raw_train_split/1780/book_07.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 16\n",
      "read book <- ./Datasets/raw_data/1780/book_05.txt\n",
      "new book filepath: ./Datasets/raw_data/1780/book_05.txt\n",
      "write book -> ./Datasets/raw_train_split/1780/book_05.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 17\n",
      "read book <- ./Datasets/raw_data/1780/book_09.txt\n",
      "new book filepath: ./Datasets/raw_data/1780/book_09.txt\n",
      "write book -> ./Datasets/raw_train_split/1780/book_09.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 18\n",
      "read book <- ./Datasets/raw_data/1780/book_04.txt\n",
      "new book filepath: ./Datasets/raw_data/1780/book_04.txt\n",
      "write book -> ./Datasets/raw_train_split/1780/book_04.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 19\n",
      "read book <- ./Datasets/raw_data/1790/book_09.txt\n",
      "new book filepath: ./Datasets/raw_data/1790/book_09.txt\n",
      "write book -> ./Datasets/raw_train_split/1790/book_09.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 20\n",
      "read book <- ./Datasets/raw_data/1790/book_10.txt\n",
      "new book filepath: ./Datasets/raw_data/1790/book_10.txt\n",
      "write book -> ./Datasets/raw_train_split/1790/book_10.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 21\n",
      "read book <- ./Datasets/raw_data/1790/book_06.txt\n",
      "new book filepath: ./Datasets/raw_data/1790/book_06.txt\n",
      "write book -> ./Datasets/raw_train_split/1790/book_06.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 22\n",
      "read book <- ./Datasets/raw_data/1790/book_03.txt\n",
      "new book filepath: ./Datasets/raw_data/1790/book_03.txt\n",
      "write book -> ./Datasets/raw_train_split/1790/book_03.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 23\n",
      "read book <- ./Datasets/raw_data/1790/book_11.txt\n",
      "new book filepath: ./Datasets/raw_data/1790/book_11.txt\n",
      "write book -> ./Datasets/raw_train_split/1790/book_11.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 24\n",
      "read book <- ./Datasets/raw_data/1790/book_02.txt\n",
      "new book filepath: ./Datasets/raw_data/1790/book_02.txt\n",
      "write book -> ./Datasets/raw_train_split/1790/book_02.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 25\n",
      "read book <- ./Datasets/raw_data/1790/book_07.txt\n",
      "new book filepath: ./Datasets/raw_data/1790/book_07.txt\n",
      "write book -> ./Datasets/raw_train_split/1790/book_07.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 26\n",
      "read book <- ./Datasets/raw_data/1790/book_01.txt\n",
      "new book filepath: ./Datasets/raw_data/1790/book_01.txt\n",
      "write book -> ./Datasets/raw_train_split/1790/book_01.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 27\n",
      "read book <- ./Datasets/raw_data/1800/book_05.txt\n",
      "new book filepath: ./Datasets/raw_data/1800/book_05.txt\n",
      "write book -> ./Datasets/raw_train_split/1800/book_05.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 28\n",
      "read book <- ./Datasets/raw_data/1800/book_09.txt\n",
      "new book filepath: ./Datasets/raw_data/1800/book_09.txt\n",
      "write book -> ./Datasets/raw_train_split/1800/book_09.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 29\n",
      "read book <- ./Datasets/raw_data/1800/book_08.txt\n",
      "new book filepath: ./Datasets/raw_data/1800/book_08.txt\n",
      "write book -> ./Datasets/raw_train_split/1800/book_08.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 30\n",
      "read book <- ./Datasets/raw_data/1800/book_03.txt\n",
      "new book filepath: ./Datasets/raw_data/1800/book_03.txt\n",
      "write book -> ./Datasets/raw_train_split/1800/book_03.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 31\n",
      "read book <- ./Datasets/raw_data/1800/book_07.txt\n",
      "new book filepath: ./Datasets/raw_data/1800/book_07.txt\n",
      "write book -> ./Datasets/raw_train_split/1800/book_07.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 32\n",
      "read book <- ./Datasets/raw_data/1800/book_10.txt\n",
      "new book filepath: ./Datasets/raw_data/1800/book_10.txt\n",
      "write book -> ./Datasets/raw_train_split/1800/book_10.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 33\n",
      "read book <- ./Datasets/raw_data/1800/book_01.txt\n",
      "new book filepath: ./Datasets/raw_data/1800/book_01.txt\n",
      "write book -> ./Datasets/raw_train_split/1800/book_01.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 34\n",
      "read book <- ./Datasets/raw_data/1800/book_02.txt\n",
      "new book filepath: ./Datasets/raw_data/1800/book_02.txt\n",
      "write book -> ./Datasets/raw_train_split/1800/book_02.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 35\n",
      "read book <- ./Datasets/raw_data/1810/book_15.txt\n",
      "new book filepath: ./Datasets/raw_data/1810/book_15.txt\n",
      "write book -> ./Datasets/raw_train_split/1810/book_15.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 36\n",
      "read book <- ./Datasets/raw_data/1810/book_14.txt\n",
      "new book filepath: ./Datasets/raw_data/1810/book_14.txt\n",
      "write book -> ./Datasets/raw_train_split/1810/book_14.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 37\n",
      "read book <- ./Datasets/raw_data/1810/book_04.txt\n",
      "new book filepath: ./Datasets/raw_data/1810/book_04.txt\n",
      "write book -> ./Datasets/raw_train_split/1810/book_04.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 38\n",
      "read book <- ./Datasets/raw_data/1810/book_06.txt\n",
      "new book filepath: ./Datasets/raw_data/1810/book_06.txt\n",
      "write book -> ./Datasets/raw_train_split/1810/book_06.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 39\n",
      "read book <- ./Datasets/raw_data/1810/book_11.txt\n",
      "new book filepath: ./Datasets/raw_data/1810/book_11.txt\n",
      "write book -> ./Datasets/raw_train_split/1810/book_11.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 40\n",
      "read book <- ./Datasets/raw_data/1810/book_03.txt\n",
      "new book filepath: ./Datasets/raw_data/1810/book_03.txt\n",
      "write book -> ./Datasets/raw_train_split/1810/book_03.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 41\n",
      "read book <- ./Datasets/raw_data/1810/book_05.txt\n",
      "new book filepath: ./Datasets/raw_data/1810/book_05.txt\n",
      "write book -> ./Datasets/raw_train_split/1810/book_05.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 42\n",
      "read book <- ./Datasets/raw_data/1810/book_10.txt\n",
      "new book filepath: ./Datasets/raw_data/1810/book_10.txt\n",
      "write book -> ./Datasets/raw_train_split/1810/book_10.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 43\n",
      "read book <- ./Datasets/raw_data/1810/book_07.txt\n",
      "new book filepath: ./Datasets/raw_data/1810/book_07.txt\n",
      "write book -> ./Datasets/raw_train_split/1810/book_07.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 44\n",
      "read book <- ./Datasets/raw_data/1810/book_02.txt\n",
      "new book filepath: ./Datasets/raw_data/1810/book_02.txt\n",
      "write book -> ./Datasets/raw_train_split/1810/book_02.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 45\n",
      "read book <- ./Datasets/raw_data/1810/book_09.txt\n",
      "new book filepath: ./Datasets/raw_data/1810/book_09.txt\n",
      "write book -> ./Datasets/raw_train_split/1810/book_09.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 46\n",
      "read book <- ./Datasets/raw_data/1810/book_08.txt\n",
      "new book filepath: ./Datasets/raw_data/1810/book_08.txt\n",
      "write book -> ./Datasets/raw_train_split/1810/book_08.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 47\n",
      "read book <- ./Datasets/raw_data/1820/book_09.txt\n",
      "new book filepath: ./Datasets/raw_data/1820/book_09.txt\n",
      "write book -> ./Datasets/raw_train_split/1820/book_09.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 48\n",
      "read book <- ./Datasets/raw_data/1820/book_03.txt\n",
      "new book filepath: ./Datasets/raw_data/1820/book_03.txt\n",
      "write book -> ./Datasets/raw_train_split/1820/book_03.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 49\n",
      "read book <- ./Datasets/raw_data/1820/book_06.txt\n",
      "new book filepath: ./Datasets/raw_data/1820/book_06.txt\n",
      "write book -> ./Datasets/raw_train_split/1820/book_06.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 50\n",
      "read book <- ./Datasets/raw_data/1820/book_10.txt\n",
      "new book filepath: ./Datasets/raw_data/1820/book_10.txt\n",
      "write book -> ./Datasets/raw_train_split/1820/book_10.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 51\n",
      "read book <- ./Datasets/raw_data/1820/book_14.txt\n",
      "new book filepath: ./Datasets/raw_data/1820/book_14.txt\n",
      "write book -> ./Datasets/raw_train_split/1820/book_14.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 52\n",
      "read book <- ./Datasets/raw_data/1820/book_08.txt\n",
      "new book filepath: ./Datasets/raw_data/1820/book_08.txt\n",
      "write book -> ./Datasets/raw_train_split/1820/book_08.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 53\n",
      "read book <- ./Datasets/raw_data/1820/book_07.txt\n",
      "new book filepath: ./Datasets/raw_data/1820/book_07.txt\n",
      "write book -> ./Datasets/raw_train_split/1820/book_07.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 54\n",
      "read book <- ./Datasets/raw_data/1820/book_13.txt\n",
      "new book filepath: ./Datasets/raw_data/1820/book_13.txt\n",
      "write book -> ./Datasets/raw_train_split/1820/book_13.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 55\n",
      "read book <- ./Datasets/raw_data/1820/book_05.txt\n",
      "new book filepath: ./Datasets/raw_data/1820/book_05.txt\n",
      "write book -> ./Datasets/raw_train_split/1820/book_05.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 56\n",
      "read book <- ./Datasets/raw_data/1820/book_04.txt\n",
      "new book filepath: ./Datasets/raw_data/1820/book_04.txt\n",
      "write book -> ./Datasets/raw_train_split/1820/book_04.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 57\n",
      "read book <- ./Datasets/raw_data/1820/book_11.txt\n",
      "new book filepath: ./Datasets/raw_data/1820/book_11.txt\n",
      "write book -> ./Datasets/raw_train_split/1820/book_11.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 58\n",
      "read book <- ./Datasets/raw_data/1830/book_07.txt\n",
      "new book filepath: ./Datasets/raw_data/1830/book_07.txt\n",
      "write book -> ./Datasets/raw_train_split/1830/book_07.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 59\n",
      "read book <- ./Datasets/raw_data/1830/book_04.txt\n",
      "new book filepath: ./Datasets/raw_data/1830/book_04.txt\n",
      "write book -> ./Datasets/raw_train_split/1830/book_04.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 60\n",
      "read book <- ./Datasets/raw_data/1830/book_05.txt\n",
      "new book filepath: ./Datasets/raw_data/1830/book_05.txt\n",
      "write book -> ./Datasets/raw_train_split/1830/book_05.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 61\n",
      "read book <- ./Datasets/raw_data/1830/book_01.txt\n",
      "new book filepath: ./Datasets/raw_data/1830/book_01.txt\n",
      "write book -> ./Datasets/raw_train_split/1830/book_01.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 62\n",
      "read book <- ./Datasets/raw_data/1830/book_10.txt\n",
      "new book filepath: ./Datasets/raw_data/1830/book_10.txt\n",
      "write book -> ./Datasets/raw_train_split/1830/book_10.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 63\n",
      "read book <- ./Datasets/raw_data/1830/book_08.txt\n",
      "new book filepath: ./Datasets/raw_data/1830/book_08.txt\n",
      "write book -> ./Datasets/raw_train_split/1830/book_08.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 64\n",
      "read book <- ./Datasets/raw_data/1830/book_02.txt\n",
      "new book filepath: ./Datasets/raw_data/1830/book_02.txt\n",
      "write book -> ./Datasets/raw_train_split/1830/book_02.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 65\n",
      "read book <- ./Datasets/raw_data/1830/book_09.txt\n",
      "new book filepath: ./Datasets/raw_data/1830/book_09.txt\n",
      "write book -> ./Datasets/raw_train_split/1830/book_09.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 66\n",
      "read book <- ./Datasets/raw_data/1830/book_12.txt\n",
      "new book filepath: ./Datasets/raw_data/1830/book_12.txt\n",
      "write book -> ./Datasets/raw_train_split/1830/book_12.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 67\n",
      "read book <- ./Datasets/raw_data/1840/book_01.txt\n",
      "new book filepath: ./Datasets/raw_data/1840/book_01.txt\n",
      "write book -> ./Datasets/raw_train_split/1840/book_01.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 68\n",
      "read book <- ./Datasets/raw_data/1840/book_11.txt\n",
      "new book filepath: ./Datasets/raw_data/1840/book_11.txt\n",
      "write book -> ./Datasets/raw_train_split/1840/book_11.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 69\n",
      "read book <- ./Datasets/raw_data/1840/book_13.txt\n",
      "new book filepath: ./Datasets/raw_data/1840/book_13.txt\n",
      "write book -> ./Datasets/raw_train_split/1840/book_13.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 70\n",
      "read book <- ./Datasets/raw_data/1840/book_02.txt\n",
      "new book filepath: ./Datasets/raw_data/1840/book_02.txt\n",
      "write book -> ./Datasets/raw_train_split/1840/book_02.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 71\n",
      "read book <- ./Datasets/raw_data/1840/book_05.txt\n",
      "new book filepath: ./Datasets/raw_data/1840/book_05.txt\n",
      "write book -> ./Datasets/raw_train_split/1840/book_05.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 72\n",
      "read book <- ./Datasets/raw_data/1840/book_06.txt\n",
      "new book filepath: ./Datasets/raw_data/1840/book_06.txt\n",
      "write book -> ./Datasets/raw_train_split/1840/book_06.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 73\n",
      "read book <- ./Datasets/raw_data/1840/book_10.txt\n",
      "new book filepath: ./Datasets/raw_data/1840/book_10.txt\n",
      "write book -> ./Datasets/raw_train_split/1840/book_10.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 74\n",
      "read book <- ./Datasets/raw_data/1840/book_07.txt\n",
      "new book filepath: ./Datasets/raw_data/1840/book_07.txt\n",
      "write book -> ./Datasets/raw_train_split/1840/book_07.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 75\n",
      "read book <- ./Datasets/raw_data/1840/book_08.txt\n",
      "new book filepath: ./Datasets/raw_data/1840/book_08.txt\n",
      "write book -> ./Datasets/raw_train_split/1840/book_08.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 76\n",
      "read book <- ./Datasets/raw_data/1840/book_03.txt\n",
      "new book filepath: ./Datasets/raw_data/1840/book_03.txt\n",
      "write book -> ./Datasets/raw_train_split/1840/book_03.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 77\n",
      "read book <- ./Datasets/raw_data/1850/book_11.txt\n",
      "new book filepath: ./Datasets/raw_data/1850/book_11.txt\n",
      "write book -> ./Datasets/raw_train_split/1850/book_11.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 78\n",
      "read book <- ./Datasets/raw_data/1850/book_05.txt\n",
      "new book filepath: ./Datasets/raw_data/1850/book_05.txt\n",
      "write book -> ./Datasets/raw_train_split/1850/book_05.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 79\n",
      "read book <- ./Datasets/raw_data/1850/book_09.txt\n",
      "new book filepath: ./Datasets/raw_data/1850/book_09.txt\n",
      "write book -> ./Datasets/raw_train_split/1850/book_09.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 80\n",
      "read book <- ./Datasets/raw_data/1850/book_08.txt\n",
      "new book filepath: ./Datasets/raw_data/1850/book_08.txt\n",
      "write book -> ./Datasets/raw_train_split/1850/book_08.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 81\n",
      "read book <- ./Datasets/raw_data/1850/book_02.txt\n",
      "new book filepath: ./Datasets/raw_data/1850/book_02.txt\n",
      "write book -> ./Datasets/raw_train_split/1850/book_02.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 82\n",
      "read book <- ./Datasets/raw_data/1850/book_10.txt\n",
      "new book filepath: ./Datasets/raw_data/1850/book_10.txt\n",
      "write book -> ./Datasets/raw_train_split/1850/book_10.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 83\n",
      "read book <- ./Datasets/raw_data/1850/book_03.txt\n",
      "new book filepath: ./Datasets/raw_data/1850/book_03.txt\n",
      "write book -> ./Datasets/raw_train_split/1850/book_03.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 84\n",
      "read book <- ./Datasets/raw_data/1850/book_07.txt\n",
      "new book filepath: ./Datasets/raw_data/1850/book_07.txt\n",
      "write book -> ./Datasets/raw_train_split/1850/book_07.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 85\n",
      "read book <- ./Datasets/raw_data/1850/book_06.txt\n",
      "new book filepath: ./Datasets/raw_data/1850/book_06.txt\n",
      "write book -> ./Datasets/raw_train_split/1850/book_06.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 86\n",
      "read book <- ./Datasets/raw_data/1850/book_12.txt\n",
      "new book filepath: ./Datasets/raw_data/1850/book_12.txt\n",
      "write book -> ./Datasets/raw_train_split/1850/book_12.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 87\n",
      "read book <- ./Datasets/raw_data/1860/book_01.txt\n",
      "new book filepath: ./Datasets/raw_data/1860/book_01.txt\n",
      "write book -> ./Datasets/raw_train_split/1860/book_01.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 88\n",
      "read book <- ./Datasets/raw_data/1860/book_06.txt\n",
      "new book filepath: ./Datasets/raw_data/1860/book_06.txt\n",
      "write book -> ./Datasets/raw_train_split/1860/book_06.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 89\n",
      "read book <- ./Datasets/raw_data/1860/book_04.txt\n",
      "new book filepath: ./Datasets/raw_data/1860/book_04.txt\n",
      "write book -> ./Datasets/raw_train_split/1860/book_04.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 90\n",
      "read book <- ./Datasets/raw_data/1860/book_09.txt\n",
      "new book filepath: ./Datasets/raw_data/1860/book_09.txt\n",
      "write book -> ./Datasets/raw_train_split/1860/book_09.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 91\n",
      "read book <- ./Datasets/raw_data/1860/book_10.txt\n",
      "new book filepath: ./Datasets/raw_data/1860/book_10.txt\n",
      "write book -> ./Datasets/raw_train_split/1860/book_10.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 92\n",
      "read book <- ./Datasets/raw_data/1860/book_12.txt\n",
      "new book filepath: ./Datasets/raw_data/1860/book_12.txt\n",
      "write book -> ./Datasets/raw_train_split/1860/book_12.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 93\n",
      "read book <- ./Datasets/raw_data/1860/book_02.txt\n",
      "new book filepath: ./Datasets/raw_data/1860/book_02.txt\n",
      "write book -> ./Datasets/raw_train_split/1860/book_02.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 94\n",
      "read book <- ./Datasets/raw_data/1860/book_05.txt\n",
      "new book filepath: ./Datasets/raw_data/1860/book_05.txt\n",
      "write book -> ./Datasets/raw_train_split/1860/book_05.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 95\n",
      "read book <- ./Datasets/raw_data/1860/book_03.txt\n",
      "new book filepath: ./Datasets/raw_data/1860/book_03.txt\n",
      "write book -> ./Datasets/raw_train_split/1860/book_03.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 96\n",
      "read book <- ./Datasets/raw_data/1870/book_02.txt\n",
      "new book filepath: ./Datasets/raw_data/1870/book_02.txt\n",
      "write book -> ./Datasets/raw_train_split/1870/book_02.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 97\n",
      "read book <- ./Datasets/raw_data/1870/book_08.txt\n",
      "new book filepath: ./Datasets/raw_data/1870/book_08.txt\n",
      "write book -> ./Datasets/raw_train_split/1870/book_08.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 98\n",
      "read book <- ./Datasets/raw_data/1870/book_12.txt\n",
      "new book filepath: ./Datasets/raw_data/1870/book_12.txt\n",
      "write book -> ./Datasets/raw_train_split/1870/book_12.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 99\n",
      "read book <- ./Datasets/raw_data/1870/book_11.txt\n",
      "new book filepath: ./Datasets/raw_data/1870/book_11.txt\n",
      "write book -> ./Datasets/raw_train_split/1870/book_11.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 100\n",
      "read book <- ./Datasets/raw_data/1870/book_01.txt\n",
      "new book filepath: ./Datasets/raw_data/1870/book_01.txt\n",
      "write book -> ./Datasets/raw_train_split/1870/book_01.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 101\n",
      "read book <- ./Datasets/raw_data/1870/book_09.txt\n",
      "new book filepath: ./Datasets/raw_data/1870/book_09.txt\n",
      "write book -> ./Datasets/raw_train_split/1870/book_09.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 102\n",
      "read book <- ./Datasets/raw_data/1870/book_05.txt\n",
      "new book filepath: ./Datasets/raw_data/1870/book_05.txt\n",
      "write book -> ./Datasets/raw_train_split/1870/book_05.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 103\n",
      "read book <- ./Datasets/raw_data/1870/book_03.txt\n",
      "new book filepath: ./Datasets/raw_data/1870/book_03.txt\n",
      "write book -> ./Datasets/raw_train_split/1870/book_03.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 104\n",
      "read book <- ./Datasets/raw_data/1870/book_04.txt\n",
      "new book filepath: ./Datasets/raw_data/1870/book_04.txt\n",
      "write book -> ./Datasets/raw_train_split/1870/book_04.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 105\n",
      "read book <- ./Datasets/raw_data/1880/book_09.txt\n",
      "new book filepath: ./Datasets/raw_data/1880/book_09.txt\n",
      "write book -> ./Datasets/raw_train_split/1880/book_09.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 106\n",
      "read book <- ./Datasets/raw_data/1880/book_01.txt\n",
      "new book filepath: ./Datasets/raw_data/1880/book_01.txt\n",
      "write book -> ./Datasets/raw_train_split/1880/book_01.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 107\n",
      "read book <- ./Datasets/raw_data/1880/book_06.txt\n",
      "new book filepath: ./Datasets/raw_data/1880/book_06.txt\n",
      "write book -> ./Datasets/raw_train_split/1880/book_06.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 108\n",
      "read book <- ./Datasets/raw_data/1880/book_12.txt\n",
      "new book filepath: ./Datasets/raw_data/1880/book_12.txt\n",
      "write book -> ./Datasets/raw_train_split/1880/book_12.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 109\n",
      "read book <- ./Datasets/raw_data/1880/book_08.txt\n",
      "new book filepath: ./Datasets/raw_data/1880/book_08.txt\n",
      "write book -> ./Datasets/raw_train_split/1880/book_08.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 110\n",
      "read book <- ./Datasets/raw_data/1880/book_05.txt\n",
      "new book filepath: ./Datasets/raw_data/1880/book_05.txt\n",
      "write book -> ./Datasets/raw_train_split/1880/book_05.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 111\n",
      "read book <- ./Datasets/raw_data/1880/book_04.txt\n",
      "new book filepath: ./Datasets/raw_data/1880/book_04.txt\n",
      "write book -> ./Datasets/raw_train_split/1880/book_04.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 112\n",
      "read book <- ./Datasets/raw_data/1880/book_10.txt\n",
      "new book filepath: ./Datasets/raw_data/1880/book_10.txt\n",
      "write book -> ./Datasets/raw_train_split/1880/book_10.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 113\n",
      "read book <- ./Datasets/raw_data/1880/book_02.txt\n",
      "new book filepath: ./Datasets/raw_data/1880/book_02.txt\n",
      "write book -> ./Datasets/raw_train_split/1880/book_02.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 114\n",
      "read book <- ./Datasets/raw_data/1890/book_08.txt\n",
      "new book filepath: ./Datasets/raw_data/1890/book_08.txt\n",
      "write book -> ./Datasets/raw_train_split/1890/book_08.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 115\n",
      "read book <- ./Datasets/raw_data/1890/book_07.txt\n",
      "new book filepath: ./Datasets/raw_data/1890/book_07.txt\n",
      "write book -> ./Datasets/raw_train_split/1890/book_07.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 116\n",
      "read book <- ./Datasets/raw_data/1890/book_10.txt\n",
      "new book filepath: ./Datasets/raw_data/1890/book_10.txt\n",
      "write book -> ./Datasets/raw_train_split/1890/book_10.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 117\n",
      "read book <- ./Datasets/raw_data/1890/book_12.txt\n",
      "new book filepath: ./Datasets/raw_data/1890/book_12.txt\n",
      "write book -> ./Datasets/raw_train_split/1890/book_12.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 118\n",
      "read book <- ./Datasets/raw_data/1890/book_04.txt\n",
      "new book filepath: ./Datasets/raw_data/1890/book_04.txt\n",
      "write book -> ./Datasets/raw_train_split/1890/book_04.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 119\n",
      "read book <- ./Datasets/raw_data/1890/book_03.txt\n",
      "new book filepath: ./Datasets/raw_data/1890/book_03.txt\n",
      "write book -> ./Datasets/raw_train_split/1890/book_03.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 120\n",
      "read book <- ./Datasets/raw_data/1890/book_01.txt\n",
      "new book filepath: ./Datasets/raw_data/1890/book_01.txt\n",
      "write book -> ./Datasets/raw_train_split/1890/book_01.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 121\n",
      "read book <- ./Datasets/raw_data/1890/book_06.txt\n",
      "new book filepath: ./Datasets/raw_data/1890/book_06.txt\n",
      "write book -> ./Datasets/raw_train_split/1890/book_06.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 122\n",
      "read book <- ./Datasets/raw_data/1890/book_05.txt\n",
      "new book filepath: ./Datasets/raw_data/1890/book_05.txt\n",
      "write book -> ./Datasets/raw_train_split/1890/book_05.txt\n",
      "wrote book successfully!!!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "write_stratified_split(raw_train, raw_train_split_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1409bc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book: 1\n",
      "read book <- ./Datasets/raw_data/1770/book_01.txt\n",
      "new book filepath: ./Datasets/raw_data/1770/book_01.txt\n",
      "write book -> ./Datasets/raw_test_split/1770/book_01.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 2\n",
      "read book <- ./Datasets/raw_data/1770/book_02.txt\n",
      "new book filepath: ./Datasets/raw_data/1770/book_02.txt\n",
      "write book -> ./Datasets/raw_test_split/1770/book_02.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 3\n",
      "read book <- ./Datasets/raw_data/1770/book_11.txt\n",
      "new book filepath: ./Datasets/raw_data/1770/book_11.txt\n",
      "write book -> ./Datasets/raw_test_split/1770/book_11.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 4\n",
      "read book <- ./Datasets/raw_data/1780/book_02.txt\n",
      "new book filepath: ./Datasets/raw_data/1780/book_02.txt\n",
      "write book -> ./Datasets/raw_test_split/1780/book_02.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 5\n",
      "read book <- ./Datasets/raw_data/1780/book_12.txt\n",
      "new book filepath: ./Datasets/raw_data/1780/book_12.txt\n",
      "write book -> ./Datasets/raw_test_split/1780/book_12.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 6\n",
      "read book <- ./Datasets/raw_data/1780/book_01.txt\n",
      "new book filepath: ./Datasets/raw_data/1780/book_01.txt\n",
      "write book -> ./Datasets/raw_test_split/1780/book_01.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 7\n",
      "read book <- ./Datasets/raw_data/1790/book_05.txt\n",
      "new book filepath: ./Datasets/raw_data/1790/book_05.txt\n",
      "write book -> ./Datasets/raw_test_split/1790/book_05.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 8\n",
      "read book <- ./Datasets/raw_data/1790/book_08.txt\n",
      "new book filepath: ./Datasets/raw_data/1790/book_08.txt\n",
      "write book -> ./Datasets/raw_test_split/1790/book_08.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 9\n",
      "read book <- ./Datasets/raw_data/1790/book_04.txt\n",
      "new book filepath: ./Datasets/raw_data/1790/book_04.txt\n",
      "write book -> ./Datasets/raw_test_split/1790/book_04.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 10\n",
      "read book <- ./Datasets/raw_data/1800/book_06.txt\n",
      "new book filepath: ./Datasets/raw_data/1800/book_06.txt\n",
      "write book -> ./Datasets/raw_test_split/1800/book_06.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 11\n",
      "read book <- ./Datasets/raw_data/1800/book_04.txt\n",
      "new book filepath: ./Datasets/raw_data/1800/book_04.txt\n",
      "write book -> ./Datasets/raw_test_split/1800/book_04.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 12\n",
      "read book <- ./Datasets/raw_data/1810/book_12.txt\n",
      "new book filepath: ./Datasets/raw_data/1810/book_12.txt\n",
      "write book -> ./Datasets/raw_test_split/1810/book_12.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 13\n",
      "read book <- ./Datasets/raw_data/1810/book_01.txt\n",
      "new book filepath: ./Datasets/raw_data/1810/book_01.txt\n",
      "write book -> ./Datasets/raw_test_split/1810/book_01.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 14\n",
      "read book <- ./Datasets/raw_data/1810/book_13.txt\n",
      "new book filepath: ./Datasets/raw_data/1810/book_13.txt\n",
      "write book -> ./Datasets/raw_test_split/1810/book_13.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 15\n",
      "read book <- ./Datasets/raw_data/1820/book_01.txt\n",
      "new book filepath: ./Datasets/raw_data/1820/book_01.txt\n",
      "write book -> ./Datasets/raw_test_split/1820/book_01.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 16\n",
      "read book <- ./Datasets/raw_data/1820/book_02.txt\n",
      "new book filepath: ./Datasets/raw_data/1820/book_02.txt\n",
      "write book -> ./Datasets/raw_test_split/1820/book_02.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 17\n",
      "read book <- ./Datasets/raw_data/1820/book_12.txt\n",
      "new book filepath: ./Datasets/raw_data/1820/book_12.txt\n",
      "write book -> ./Datasets/raw_test_split/1820/book_12.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 18\n",
      "read book <- ./Datasets/raw_data/1830/book_03.txt\n",
      "new book filepath: ./Datasets/raw_data/1830/book_03.txt\n",
      "write book -> ./Datasets/raw_test_split/1830/book_03.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 19\n",
      "read book <- ./Datasets/raw_data/1830/book_06.txt\n",
      "new book filepath: ./Datasets/raw_data/1830/book_06.txt\n",
      "write book -> ./Datasets/raw_test_split/1830/book_06.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 20\n",
      "read book <- ./Datasets/raw_data/1830/book_11.txt\n",
      "new book filepath: ./Datasets/raw_data/1830/book_11.txt\n",
      "write book -> ./Datasets/raw_test_split/1830/book_11.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 21\n",
      "read book <- ./Datasets/raw_data/1840/book_04.txt\n",
      "new book filepath: ./Datasets/raw_data/1840/book_04.txt\n",
      "write book -> ./Datasets/raw_test_split/1840/book_04.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 22\n",
      "read book <- ./Datasets/raw_data/1840/book_12.txt\n",
      "new book filepath: ./Datasets/raw_data/1840/book_12.txt\n",
      "write book -> ./Datasets/raw_test_split/1840/book_12.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 23\n",
      "read book <- ./Datasets/raw_data/1840/book_09.txt\n",
      "new book filepath: ./Datasets/raw_data/1840/book_09.txt\n",
      "write book -> ./Datasets/raw_test_split/1840/book_09.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 24\n",
      "read book <- ./Datasets/raw_data/1850/book_04.txt\n",
      "new book filepath: ./Datasets/raw_data/1850/book_04.txt\n",
      "write book -> ./Datasets/raw_test_split/1850/book_04.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 25\n",
      "read book <- ./Datasets/raw_data/1850/book_01.txt\n",
      "new book filepath: ./Datasets/raw_data/1850/book_01.txt\n",
      "write book -> ./Datasets/raw_test_split/1850/book_01.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 26\n",
      "read book <- ./Datasets/raw_data/1850/book_13.txt\n",
      "new book filepath: ./Datasets/raw_data/1850/book_13.txt\n",
      "write book -> ./Datasets/raw_test_split/1850/book_13.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 27\n",
      "read book <- ./Datasets/raw_data/1860/book_08.txt\n",
      "new book filepath: ./Datasets/raw_data/1860/book_08.txt\n",
      "write book -> ./Datasets/raw_test_split/1860/book_08.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 28\n",
      "read book <- ./Datasets/raw_data/1860/book_11.txt\n",
      "new book filepath: ./Datasets/raw_data/1860/book_11.txt\n",
      "write book -> ./Datasets/raw_test_split/1860/book_11.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 29\n",
      "read book <- ./Datasets/raw_data/1860/book_07.txt\n",
      "new book filepath: ./Datasets/raw_data/1860/book_07.txt\n",
      "write book -> ./Datasets/raw_test_split/1860/book_07.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 30\n",
      "read book <- ./Datasets/raw_data/1870/book_06.txt\n",
      "new book filepath: ./Datasets/raw_data/1870/book_06.txt\n",
      "write book -> ./Datasets/raw_test_split/1870/book_06.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 31\n",
      "read book <- ./Datasets/raw_data/1870/book_07.txt\n",
      "new book filepath: ./Datasets/raw_data/1870/book_07.txt\n",
      "write book -> ./Datasets/raw_test_split/1870/book_07.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 32\n",
      "read book <- ./Datasets/raw_data/1870/book_10.txt\n",
      "new book filepath: ./Datasets/raw_data/1870/book_10.txt\n",
      "write book -> ./Datasets/raw_test_split/1870/book_10.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 33\n",
      "read book <- ./Datasets/raw_data/1880/book_07.txt\n",
      "new book filepath: ./Datasets/raw_data/1880/book_07.txt\n",
      "write book -> ./Datasets/raw_test_split/1880/book_07.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 34\n",
      "read book <- ./Datasets/raw_data/1880/book_03.txt\n",
      "new book filepath: ./Datasets/raw_data/1880/book_03.txt\n",
      "write book -> ./Datasets/raw_test_split/1880/book_03.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 35\n",
      "read book <- ./Datasets/raw_data/1880/book_11.txt\n",
      "new book filepath: ./Datasets/raw_data/1880/book_11.txt\n",
      "write book -> ./Datasets/raw_test_split/1880/book_11.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 36\n",
      "read book <- ./Datasets/raw_data/1890/book_09.txt\n",
      "new book filepath: ./Datasets/raw_data/1890/book_09.txt\n",
      "write book -> ./Datasets/raw_test_split/1890/book_09.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 37\n",
      "read book <- ./Datasets/raw_data/1890/book_02.txt\n",
      "new book filepath: ./Datasets/raw_data/1890/book_02.txt\n",
      "write book -> ./Datasets/raw_test_split/1890/book_02.txt\n",
      "wrote book successfully!!!\n",
      "\n",
      "book: 38\n",
      "read book <- ./Datasets/raw_data/1890/book_11.txt\n",
      "new book filepath: ./Datasets/raw_data/1890/book_11.txt\n",
      "write book -> ./Datasets/raw_test_split/1890/book_11.txt\n",
      "wrote book successfully!!!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "write_stratified_split(raw_test, raw_test_split_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66beed86",
   "metadata": {},
   "source": [
    "## Data-Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efd203c",
   "metadata": {},
   "source": [
    "## Data-Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fd4c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "This function uses regex expressions to clean up the data. It removes mentiones of the year as specified in the project instructions \n",
    "as well as the header, footer and whitespace in the project gutenburg books\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    # remove everything up to and including start\n",
    "    start_match = re.search(\n",
    "        r\"\\*\\*\\* START OF.*?\\*\\*\\*\", text, re.IGNORECASE | re.DOTALL\n",
    "    )\n",
    "    if start_match:\n",
    "        text = text[start_match.end() :]\n",
    "\n",
    "    # remove everything after end\n",
    "    end_match = re.search(r\"\\*\\*\\* END OF.*?\\*\\*\\*\", text, re.IGNORECASE | re.DOTALL)\n",
    "    if end_match:\n",
    "        text = text[: end_match.start()]\n",
    "\n",
    "    # remove years\n",
    "    text = re.sub(r\"\\b1[0-9]{3}\\b\", \"\", text)\n",
    "\n",
    "    # remove whitespace\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b776fa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function cleans up the data in the stratified split using the clean function \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def clean_stratified_split(raw_split_path, clean_split_path):\n",
    "    decade_dirs = [\n",
    "        dir\n",
    "        for dir in os.listdir(raw_split_path)\n",
    "        if os.path.isdir(os.path.join(raw_split_path, dir))\n",
    "    ]\n",
    "    decade_dirs.sort()\n",
    "\n",
    "    total_books = 0\n",
    "    for decade_dir in decade_dirs:\n",
    "        clean_decade_path = os.path.join(clean_split_path, decade_dir)\n",
    "        print(f\"clean decade path: {clean_decade_path}\")\n",
    "        if not os.path.exists(clean_decade_path):\n",
    "            os.makedirs(clean_decade_path)\n",
    "        raw_decade_path = os.path.join(raw_split_path, decade_dir)\n",
    "        print(f\"raw decade path: {raw_decade_path}\")\n",
    "        text_files = [f for f in os.listdir(raw_decade_path) if f.endswith(\".txt\")]\n",
    "\n",
    "        for text_file in text_files:\n",
    "            total_books += 1\n",
    "            print(f\"books processed: {total_books}\")\n",
    "            raw_file_path = os.path.join(raw_decade_path, text_file)\n",
    "            # print(f\"raw data path: {raw_file_path}\")\n",
    "            clean_file_path = os.path.join(clean_decade_path, text_file)\n",
    "            # print(f\"clean file path: {clean_file_path}\")\n",
    "            print(\n",
    "                f\"read raw data: {raw_file_path} -> clean data -> write clean data: {clean_file_path}\"\n",
    "            )\n",
    "            with open(raw_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                raw_data = f.read()\n",
    "                print(f\"read raw data <- {raw_file_path}\")\n",
    "\n",
    "            cleaned_data = clean_text(raw_data)\n",
    "            with open(clean_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(cleaned_data)\n",
    "                print(f\"write clean data -> {clean_file_path}\")\n",
    "\n",
    "            print(f\"wrote cleaned data successfully!!!\")\n",
    "            print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "98977dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean decade path: ./Datasets/clean_train_split/1770\n",
      "raw decade path: ./Datasets/raw_train_split/1770\n",
      "books processed: 1\n",
      "read raw data: ./Datasets/raw_train_split/1770/book_03.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1770/book_03.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1770/book_03.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1770/book_03.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 2\n",
      "read raw data: ./Datasets/raw_train_split/1770/book_12.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1770/book_12.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1770/book_12.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1770/book_12.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 3\n",
      "read raw data: ./Datasets/raw_train_split/1770/book_06.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1770/book_06.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1770/book_06.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1770/book_06.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 4\n",
      "read raw data: ./Datasets/raw_train_split/1770/book_07.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1770/book_07.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1770/book_07.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1770/book_07.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 5\n",
      "read raw data: ./Datasets/raw_train_split/1770/book_05.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1770/book_05.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1770/book_05.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1770/book_05.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 6\n",
      "read raw data: ./Datasets/raw_train_split/1770/book_10.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1770/book_10.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1770/book_10.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1770/book_10.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 7\n",
      "read raw data: ./Datasets/raw_train_split/1770/book_04.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1770/book_04.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1770/book_04.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1770/book_04.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 8\n",
      "read raw data: ./Datasets/raw_train_split/1770/book_09.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1770/book_09.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1770/book_09.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1770/book_09.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 9\n",
      "read raw data: ./Datasets/raw_train_split/1770/book_08.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1770/book_08.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1770/book_08.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1770/book_08.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "clean decade path: ./Datasets/clean_train_split/1780\n",
      "raw decade path: ./Datasets/raw_train_split/1780\n",
      "books processed: 10\n",
      "read raw data: ./Datasets/raw_train_split/1780/book_03.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1780/book_03.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1780/book_03.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1780/book_03.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 11\n",
      "read raw data: ./Datasets/raw_train_split/1780/book_06.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1780/book_06.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1780/book_06.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1780/book_06.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 12\n",
      "read raw data: ./Datasets/raw_train_split/1780/book_07.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1780/book_07.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1780/book_07.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1780/book_07.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 13\n",
      "read raw data: ./Datasets/raw_train_split/1780/book_05.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1780/book_05.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1780/book_05.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1780/book_05.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 14\n",
      "read raw data: ./Datasets/raw_train_split/1780/book_11.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1780/book_11.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1780/book_11.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1780/book_11.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 15\n",
      "read raw data: ./Datasets/raw_train_split/1780/book_10.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1780/book_10.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1780/book_10.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1780/book_10.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 16\n",
      "read raw data: ./Datasets/raw_train_split/1780/book_04.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1780/book_04.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1780/book_04.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1780/book_04.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 17\n",
      "read raw data: ./Datasets/raw_train_split/1780/book_09.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1780/book_09.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1780/book_09.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1780/book_09.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 18\n",
      "read raw data: ./Datasets/raw_train_split/1780/book_08.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1780/book_08.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1780/book_08.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1780/book_08.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "clean decade path: ./Datasets/clean_train_split/1790\n",
      "raw decade path: ./Datasets/raw_train_split/1790\n",
      "books processed: 19\n",
      "read raw data: ./Datasets/raw_train_split/1790/book_01.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1790/book_01.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1790/book_01.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1790/book_01.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 20\n",
      "read raw data: ./Datasets/raw_train_split/1790/book_03.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1790/book_03.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1790/book_03.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1790/book_03.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 21\n",
      "read raw data: ./Datasets/raw_train_split/1790/book_02.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1790/book_02.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1790/book_02.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1790/book_02.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 22\n",
      "read raw data: ./Datasets/raw_train_split/1790/book_06.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1790/book_06.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1790/book_06.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1790/book_06.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 23\n",
      "read raw data: ./Datasets/raw_train_split/1790/book_07.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1790/book_07.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1790/book_07.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1790/book_07.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 24\n",
      "read raw data: ./Datasets/raw_train_split/1790/book_11.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1790/book_11.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1790/book_11.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1790/book_11.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 25\n",
      "read raw data: ./Datasets/raw_train_split/1790/book_10.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1790/book_10.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1790/book_10.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1790/book_10.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 26\n",
      "read raw data: ./Datasets/raw_train_split/1790/book_09.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1790/book_09.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1790/book_09.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1790/book_09.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "clean decade path: ./Datasets/clean_train_split/1800\n",
      "raw decade path: ./Datasets/raw_train_split/1800\n",
      "books processed: 27\n",
      "read raw data: ./Datasets/raw_train_split/1800/book_01.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1800/book_01.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1800/book_01.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1800/book_01.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 28\n",
      "read raw data: ./Datasets/raw_train_split/1800/book_03.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1800/book_03.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1800/book_03.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1800/book_03.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 29\n",
      "read raw data: ./Datasets/raw_train_split/1800/book_02.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1800/book_02.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1800/book_02.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1800/book_02.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 30\n",
      "read raw data: ./Datasets/raw_train_split/1800/book_07.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1800/book_07.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1800/book_07.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1800/book_07.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 31\n",
      "read raw data: ./Datasets/raw_train_split/1800/book_05.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1800/book_05.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1800/book_05.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1800/book_05.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 32\n",
      "read raw data: ./Datasets/raw_train_split/1800/book_10.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1800/book_10.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1800/book_10.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1800/book_10.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 33\n",
      "read raw data: ./Datasets/raw_train_split/1800/book_09.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1800/book_09.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1800/book_09.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1800/book_09.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 34\n",
      "read raw data: ./Datasets/raw_train_split/1800/book_08.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1800/book_08.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1800/book_08.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1800/book_08.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "clean decade path: ./Datasets/clean_train_split/1810\n",
      "raw decade path: ./Datasets/raw_train_split/1810\n",
      "books processed: 35\n",
      "read raw data: ./Datasets/raw_train_split/1810/book_14.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1810/book_14.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1810/book_14.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1810/book_14.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 36\n",
      "read raw data: ./Datasets/raw_train_split/1810/book_15.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1810/book_15.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1810/book_15.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1810/book_15.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 37\n",
      "read raw data: ./Datasets/raw_train_split/1810/book_03.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1810/book_03.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1810/book_03.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1810/book_03.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 38\n",
      "read raw data: ./Datasets/raw_train_split/1810/book_02.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1810/book_02.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1810/book_02.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1810/book_02.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 39\n",
      "read raw data: ./Datasets/raw_train_split/1810/book_06.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1810/book_06.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1810/book_06.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1810/book_06.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 40\n",
      "read raw data: ./Datasets/raw_train_split/1810/book_07.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1810/book_07.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1810/book_07.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1810/book_07.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 41\n",
      "read raw data: ./Datasets/raw_train_split/1810/book_05.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1810/book_05.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1810/book_05.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1810/book_05.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 42\n",
      "read raw data: ./Datasets/raw_train_split/1810/book_11.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1810/book_11.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1810/book_11.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1810/book_11.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 43\n",
      "read raw data: ./Datasets/raw_train_split/1810/book_10.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1810/book_10.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1810/book_10.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1810/book_10.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 44\n",
      "read raw data: ./Datasets/raw_train_split/1810/book_04.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1810/book_04.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1810/book_04.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1810/book_04.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 45\n",
      "read raw data: ./Datasets/raw_train_split/1810/book_09.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1810/book_09.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1810/book_09.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1810/book_09.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 46\n",
      "read raw data: ./Datasets/raw_train_split/1810/book_08.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1810/book_08.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1810/book_08.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1810/book_08.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "clean decade path: ./Datasets/clean_train_split/1820\n",
      "raw decade path: ./Datasets/raw_train_split/1820\n",
      "books processed: 47\n",
      "read raw data: ./Datasets/raw_train_split/1820/book_14.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1820/book_14.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1820/book_14.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1820/book_14.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 48\n",
      "read raw data: ./Datasets/raw_train_split/1820/book_03.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1820/book_03.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1820/book_03.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1820/book_03.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 49\n",
      "read raw data: ./Datasets/raw_train_split/1820/book_06.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1820/book_06.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1820/book_06.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1820/book_06.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 50\n",
      "read raw data: ./Datasets/raw_train_split/1820/book_07.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1820/book_07.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1820/book_07.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1820/book_07.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 51\n",
      "read raw data: ./Datasets/raw_train_split/1820/book_13.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1820/book_13.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1820/book_13.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1820/book_13.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 52\n",
      "read raw data: ./Datasets/raw_train_split/1820/book_05.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1820/book_05.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1820/book_05.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1820/book_05.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 53\n",
      "read raw data: ./Datasets/raw_train_split/1820/book_11.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1820/book_11.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1820/book_11.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1820/book_11.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 54\n",
      "read raw data: ./Datasets/raw_train_split/1820/book_10.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1820/book_10.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1820/book_10.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1820/book_10.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 55\n",
      "read raw data: ./Datasets/raw_train_split/1820/book_04.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1820/book_04.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1820/book_04.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1820/book_04.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 56\n",
      "read raw data: ./Datasets/raw_train_split/1820/book_09.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1820/book_09.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1820/book_09.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1820/book_09.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 57\n",
      "read raw data: ./Datasets/raw_train_split/1820/book_08.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1820/book_08.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1820/book_08.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1820/book_08.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "clean decade path: ./Datasets/clean_train_split/1830\n",
      "raw decade path: ./Datasets/raw_train_split/1830\n",
      "books processed: 58\n",
      "read raw data: ./Datasets/raw_train_split/1830/book_01.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1830/book_01.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1830/book_01.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1830/book_01.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 59\n",
      "read raw data: ./Datasets/raw_train_split/1830/book_02.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1830/book_02.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1830/book_02.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1830/book_02.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 60\n",
      "read raw data: ./Datasets/raw_train_split/1830/book_12.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1830/book_12.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1830/book_12.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1830/book_12.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 61\n",
      "read raw data: ./Datasets/raw_train_split/1830/book_07.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1830/book_07.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1830/book_07.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1830/book_07.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 62\n",
      "read raw data: ./Datasets/raw_train_split/1830/book_05.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1830/book_05.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1830/book_05.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1830/book_05.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 63\n",
      "read raw data: ./Datasets/raw_train_split/1830/book_10.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1830/book_10.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1830/book_10.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1830/book_10.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 64\n",
      "read raw data: ./Datasets/raw_train_split/1830/book_04.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1830/book_04.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1830/book_04.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1830/book_04.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 65\n",
      "read raw data: ./Datasets/raw_train_split/1830/book_09.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1830/book_09.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1830/book_09.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1830/book_09.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 66\n",
      "read raw data: ./Datasets/raw_train_split/1830/book_08.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1830/book_08.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1830/book_08.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1830/book_08.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "clean decade path: ./Datasets/clean_train_split/1840\n",
      "raw decade path: ./Datasets/raw_train_split/1840\n",
      "books processed: 67\n",
      "read raw data: ./Datasets/raw_train_split/1840/book_01.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1840/book_01.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1840/book_01.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1840/book_01.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 68\n",
      "read raw data: ./Datasets/raw_train_split/1840/book_03.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1840/book_03.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1840/book_03.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1840/book_03.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 69\n",
      "read raw data: ./Datasets/raw_train_split/1840/book_02.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1840/book_02.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1840/book_02.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1840/book_02.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 70\n",
      "read raw data: ./Datasets/raw_train_split/1840/book_06.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1840/book_06.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1840/book_06.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1840/book_06.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 71\n",
      "read raw data: ./Datasets/raw_train_split/1840/book_07.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1840/book_07.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1840/book_07.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1840/book_07.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 72\n",
      "read raw data: ./Datasets/raw_train_split/1840/book_13.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1840/book_13.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1840/book_13.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1840/book_13.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 73\n",
      "read raw data: ./Datasets/raw_train_split/1840/book_05.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1840/book_05.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1840/book_05.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1840/book_05.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 74\n",
      "read raw data: ./Datasets/raw_train_split/1840/book_11.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1840/book_11.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1840/book_11.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1840/book_11.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 75\n",
      "read raw data: ./Datasets/raw_train_split/1840/book_10.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1840/book_10.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1840/book_10.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1840/book_10.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 76\n",
      "read raw data: ./Datasets/raw_train_split/1840/book_08.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1840/book_08.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1840/book_08.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1840/book_08.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "clean decade path: ./Datasets/clean_train_split/1850\n",
      "raw decade path: ./Datasets/raw_train_split/1850\n",
      "books processed: 77\n",
      "read raw data: ./Datasets/raw_train_split/1850/book_03.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1850/book_03.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1850/book_03.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1850/book_03.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 78\n",
      "read raw data: ./Datasets/raw_train_split/1850/book_02.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1850/book_02.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1850/book_02.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1850/book_02.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 79\n",
      "read raw data: ./Datasets/raw_train_split/1850/book_12.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1850/book_12.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1850/book_12.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1850/book_12.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 80\n",
      "read raw data: ./Datasets/raw_train_split/1850/book_06.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1850/book_06.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1850/book_06.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1850/book_06.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 81\n",
      "read raw data: ./Datasets/raw_train_split/1850/book_07.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1850/book_07.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1850/book_07.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1850/book_07.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 82\n",
      "read raw data: ./Datasets/raw_train_split/1850/book_05.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1850/book_05.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1850/book_05.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1850/book_05.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 83\n",
      "read raw data: ./Datasets/raw_train_split/1850/book_11.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1850/book_11.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1850/book_11.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1850/book_11.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 84\n",
      "read raw data: ./Datasets/raw_train_split/1850/book_10.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1850/book_10.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1850/book_10.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1850/book_10.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 85\n",
      "read raw data: ./Datasets/raw_train_split/1850/book_09.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1850/book_09.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1850/book_09.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1850/book_09.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 86\n",
      "read raw data: ./Datasets/raw_train_split/1850/book_08.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1850/book_08.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1850/book_08.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1850/book_08.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "clean decade path: ./Datasets/clean_train_split/1860\n",
      "raw decade path: ./Datasets/raw_train_split/1860\n",
      "books processed: 87\n",
      "read raw data: ./Datasets/raw_train_split/1860/book_01.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1860/book_01.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1860/book_01.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1860/book_01.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 88\n",
      "read raw data: ./Datasets/raw_train_split/1860/book_03.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1860/book_03.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1860/book_03.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1860/book_03.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 89\n",
      "read raw data: ./Datasets/raw_train_split/1860/book_02.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1860/book_02.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1860/book_02.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1860/book_02.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 90\n",
      "read raw data: ./Datasets/raw_train_split/1860/book_12.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1860/book_12.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1860/book_12.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1860/book_12.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 91\n",
      "read raw data: ./Datasets/raw_train_split/1860/book_06.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1860/book_06.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1860/book_06.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1860/book_06.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 92\n",
      "read raw data: ./Datasets/raw_train_split/1860/book_05.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1860/book_05.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1860/book_05.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1860/book_05.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 93\n",
      "read raw data: ./Datasets/raw_train_split/1860/book_10.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1860/book_10.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1860/book_10.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1860/book_10.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 94\n",
      "read raw data: ./Datasets/raw_train_split/1860/book_04.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1860/book_04.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1860/book_04.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1860/book_04.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 95\n",
      "read raw data: ./Datasets/raw_train_split/1860/book_09.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1860/book_09.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1860/book_09.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1860/book_09.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "clean decade path: ./Datasets/clean_train_split/1870\n",
      "raw decade path: ./Datasets/raw_train_split/1870\n",
      "books processed: 96\n",
      "read raw data: ./Datasets/raw_train_split/1870/book_01.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1870/book_01.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1870/book_01.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1870/book_01.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 97\n",
      "read raw data: ./Datasets/raw_train_split/1870/book_03.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1870/book_03.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1870/book_03.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1870/book_03.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 98\n",
      "read raw data: ./Datasets/raw_train_split/1870/book_02.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1870/book_02.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1870/book_02.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1870/book_02.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 99\n",
      "read raw data: ./Datasets/raw_train_split/1870/book_12.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1870/book_12.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1870/book_12.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1870/book_12.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 100\n",
      "read raw data: ./Datasets/raw_train_split/1870/book_05.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1870/book_05.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1870/book_05.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1870/book_05.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 101\n",
      "read raw data: ./Datasets/raw_train_split/1870/book_11.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1870/book_11.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1870/book_11.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1870/book_11.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 102\n",
      "read raw data: ./Datasets/raw_train_split/1870/book_04.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1870/book_04.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1870/book_04.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1870/book_04.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 103\n",
      "read raw data: ./Datasets/raw_train_split/1870/book_09.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1870/book_09.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1870/book_09.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1870/book_09.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 104\n",
      "read raw data: ./Datasets/raw_train_split/1870/book_08.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1870/book_08.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1870/book_08.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1870/book_08.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "clean decade path: ./Datasets/clean_train_split/1880\n",
      "raw decade path: ./Datasets/raw_train_split/1880\n",
      "books processed: 105\n",
      "read raw data: ./Datasets/raw_train_split/1880/book_01.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1880/book_01.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1880/book_01.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1880/book_01.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 106\n",
      "read raw data: ./Datasets/raw_train_split/1880/book_02.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1880/book_02.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1880/book_02.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1880/book_02.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 107\n",
      "read raw data: ./Datasets/raw_train_split/1880/book_12.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1880/book_12.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1880/book_12.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1880/book_12.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 108\n",
      "read raw data: ./Datasets/raw_train_split/1880/book_06.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1880/book_06.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1880/book_06.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1880/book_06.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 109\n",
      "read raw data: ./Datasets/raw_train_split/1880/book_05.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1880/book_05.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1880/book_05.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1880/book_05.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 110\n",
      "read raw data: ./Datasets/raw_train_split/1880/book_10.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1880/book_10.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1880/book_10.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1880/book_10.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 111\n",
      "read raw data: ./Datasets/raw_train_split/1880/book_04.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1880/book_04.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1880/book_04.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1880/book_04.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 112\n",
      "read raw data: ./Datasets/raw_train_split/1880/book_09.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1880/book_09.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1880/book_09.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1880/book_09.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 113\n",
      "read raw data: ./Datasets/raw_train_split/1880/book_08.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1880/book_08.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1880/book_08.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1880/book_08.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "clean decade path: ./Datasets/clean_train_split/1890\n",
      "raw decade path: ./Datasets/raw_train_split/1890\n",
      "books processed: 114\n",
      "read raw data: ./Datasets/raw_train_split/1890/book_01.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1890/book_01.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1890/book_01.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1890/book_01.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 115\n",
      "read raw data: ./Datasets/raw_train_split/1890/book_03.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1890/book_03.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1890/book_03.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1890/book_03.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 116\n",
      "read raw data: ./Datasets/raw_train_split/1890/book_12.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1890/book_12.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1890/book_12.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1890/book_12.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 117\n",
      "read raw data: ./Datasets/raw_train_split/1890/book_06.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1890/book_06.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1890/book_06.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1890/book_06.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 118\n",
      "read raw data: ./Datasets/raw_train_split/1890/book_07.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1890/book_07.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1890/book_07.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1890/book_07.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 119\n",
      "read raw data: ./Datasets/raw_train_split/1890/book_05.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1890/book_05.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1890/book_05.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1890/book_05.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 120\n",
      "read raw data: ./Datasets/raw_train_split/1890/book_10.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1890/book_10.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1890/book_10.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1890/book_10.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 121\n",
      "read raw data: ./Datasets/raw_train_split/1890/book_04.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1890/book_04.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1890/book_04.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1890/book_04.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 122\n",
      "read raw data: ./Datasets/raw_train_split/1890/book_08.txt -> clean data -> write clean data: ./Datasets/clean_train_split/1890/book_08.txt\n",
      "read raw data <- ./Datasets/raw_train_split/1890/book_08.txt\n",
      "write clean data -> ./Datasets/clean_train_split/1890/book_08.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clean_stratified_split(raw_train_split_path, clean_train_split_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "778f4c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean decade path: ./Datasets/clean_test_split/1770\n",
      "raw decade path: ./Datasets/raw_test_split/1770\n",
      "books processed: 1\n",
      "read raw data: ./Datasets/raw_test_split/1770/book_01.txt -> clean data -> write clean data: ./Datasets/clean_test_split/1770/book_01.txt\n",
      "read raw data <- ./Datasets/raw_test_split/1770/book_01.txt\n",
      "write clean data -> ./Datasets/clean_test_split/1770/book_01.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 2\n",
      "read raw data: ./Datasets/raw_test_split/1770/book_02.txt -> clean data -> write clean data: ./Datasets/clean_test_split/1770/book_02.txt\n",
      "read raw data <- ./Datasets/raw_test_split/1770/book_02.txt\n",
      "write clean data -> ./Datasets/clean_test_split/1770/book_02.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 3\n",
      "read raw data: ./Datasets/raw_test_split/1770/book_11.txt -> clean data -> write clean data: ./Datasets/clean_test_split/1770/book_11.txt\n",
      "read raw data <- ./Datasets/raw_test_split/1770/book_11.txt\n",
      "write clean data -> ./Datasets/clean_test_split/1770/book_11.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "clean decade path: ./Datasets/clean_test_split/1780\n",
      "raw decade path: ./Datasets/raw_test_split/1780\n",
      "books processed: 4\n",
      "read raw data: ./Datasets/raw_test_split/1780/book_01.txt -> clean data -> write clean data: ./Datasets/clean_test_split/1780/book_01.txt\n",
      "read raw data <- ./Datasets/raw_test_split/1780/book_01.txt\n",
      "write clean data -> ./Datasets/clean_test_split/1780/book_01.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 5\n",
      "read raw data: ./Datasets/raw_test_split/1780/book_02.txt -> clean data -> write clean data: ./Datasets/clean_test_split/1780/book_02.txt\n",
      "read raw data <- ./Datasets/raw_test_split/1780/book_02.txt\n",
      "write clean data -> ./Datasets/clean_test_split/1780/book_02.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 6\n",
      "read raw data: ./Datasets/raw_test_split/1780/book_12.txt -> clean data -> write clean data: ./Datasets/clean_test_split/1780/book_12.txt\n",
      "read raw data <- ./Datasets/raw_test_split/1780/book_12.txt\n",
      "write clean data -> ./Datasets/clean_test_split/1780/book_12.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "clean decade path: ./Datasets/clean_test_split/1790\n",
      "raw decade path: ./Datasets/raw_test_split/1790\n",
      "books processed: 7\n",
      "read raw data: ./Datasets/raw_test_split/1790/book_05.txt -> clean data -> write clean data: ./Datasets/clean_test_split/1790/book_05.txt\n",
      "read raw data <- ./Datasets/raw_test_split/1790/book_05.txt\n",
      "write clean data -> ./Datasets/clean_test_split/1790/book_05.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 8\n",
      "read raw data: ./Datasets/raw_test_split/1790/book_04.txt -> clean data -> write clean data: ./Datasets/clean_test_split/1790/book_04.txt\n",
      "read raw data <- ./Datasets/raw_test_split/1790/book_04.txt\n",
      "write clean data -> ./Datasets/clean_test_split/1790/book_04.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 9\n",
      "read raw data: ./Datasets/raw_test_split/1790/book_08.txt -> clean data -> write clean data: ./Datasets/clean_test_split/1790/book_08.txt\n",
      "read raw data <- ./Datasets/raw_test_split/1790/book_08.txt\n",
      "write clean data -> ./Datasets/clean_test_split/1790/book_08.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "clean decade path: ./Datasets/clean_test_split/1800\n",
      "raw decade path: ./Datasets/raw_test_split/1800\n",
      "books processed: 10\n",
      "read raw data: ./Datasets/raw_test_split/1800/book_06.txt -> clean data -> write clean data: ./Datasets/clean_test_split/1800/book_06.txt\n",
      "read raw data <- ./Datasets/raw_test_split/1800/book_06.txt\n",
      "write clean data -> ./Datasets/clean_test_split/1800/book_06.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 11\n",
      "read raw data: ./Datasets/raw_test_split/1800/book_04.txt -> clean data -> write clean data: ./Datasets/clean_test_split/1800/book_04.txt\n",
      "read raw data <- ./Datasets/raw_test_split/1800/book_04.txt\n",
      "write clean data -> ./Datasets/clean_test_split/1800/book_04.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "clean decade path: ./Datasets/clean_test_split/1810\n",
      "raw decade path: ./Datasets/raw_test_split/1810\n",
      "books processed: 12\n",
      "read raw data: ./Datasets/raw_test_split/1810/book_01.txt -> clean data -> write clean data: ./Datasets/clean_test_split/1810/book_01.txt\n",
      "read raw data <- ./Datasets/raw_test_split/1810/book_01.txt\n",
      "write clean data -> ./Datasets/clean_test_split/1810/book_01.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 13\n",
      "read raw data: ./Datasets/raw_test_split/1810/book_12.txt -> clean data -> write clean data: ./Datasets/clean_test_split/1810/book_12.txt\n",
      "read raw data <- ./Datasets/raw_test_split/1810/book_12.txt\n",
      "write clean data -> ./Datasets/clean_test_split/1810/book_12.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 14\n",
      "read raw data: ./Datasets/raw_test_split/1810/book_13.txt -> clean data -> write clean data: ./Datasets/clean_test_split/1810/book_13.txt\n",
      "read raw data <- ./Datasets/raw_test_split/1810/book_13.txt\n",
      "write clean data -> ./Datasets/clean_test_split/1810/book_13.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "clean decade path: ./Datasets/clean_test_split/1820\n",
      "raw decade path: ./Datasets/raw_test_split/1820\n",
      "books processed: 15\n",
      "read raw data: ./Datasets/raw_test_split/1820/book_01.txt -> clean data -> write clean data: ./Datasets/clean_test_split/1820/book_01.txt\n",
      "read raw data <- ./Datasets/raw_test_split/1820/book_01.txt\n",
      "write clean data -> ./Datasets/clean_test_split/1820/book_01.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 16\n",
      "read raw data: ./Datasets/raw_test_split/1820/book_02.txt -> clean data -> write clean data: ./Datasets/clean_test_split/1820/book_02.txt\n",
      "read raw data <- ./Datasets/raw_test_split/1820/book_02.txt\n",
      "write clean data -> ./Datasets/clean_test_split/1820/book_02.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 17\n",
      "read raw data: ./Datasets/raw_test_split/1820/book_12.txt -> clean data -> write clean data: ./Datasets/clean_test_split/1820/book_12.txt\n",
      "read raw data <- ./Datasets/raw_test_split/1820/book_12.txt\n",
      "write clean data -> ./Datasets/clean_test_split/1820/book_12.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "clean decade path: ./Datasets/clean_test_split/1830\n",
      "raw decade path: ./Datasets/raw_test_split/1830\n",
      "books processed: 18\n",
      "read raw data: ./Datasets/raw_test_split/1830/book_03.txt -> clean data -> write clean data: ./Datasets/clean_test_split/1830/book_03.txt\n",
      "read raw data <- ./Datasets/raw_test_split/1830/book_03.txt\n",
      "write clean data -> ./Datasets/clean_test_split/1830/book_03.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 19\n",
      "read raw data: ./Datasets/raw_test_split/1830/book_06.txt -> clean data -> write clean data: ./Datasets/clean_test_split/1830/book_06.txt\n",
      "read raw data <- ./Datasets/raw_test_split/1830/book_06.txt\n",
      "write clean data -> ./Datasets/clean_test_split/1830/book_06.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 20\n",
      "read raw data: ./Datasets/raw_test_split/1830/book_11.txt -> clean data -> write clean data: ./Datasets/clean_test_split/1830/book_11.txt\n",
      "read raw data <- ./Datasets/raw_test_split/1830/book_11.txt\n",
      "write clean data -> ./Datasets/clean_test_split/1830/book_11.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "clean decade path: ./Datasets/clean_test_split/1840\n",
      "raw decade path: ./Datasets/raw_test_split/1840\n",
      "books processed: 21\n",
      "read raw data: ./Datasets/raw_test_split/1840/book_12.txt -> clean data -> write clean data: ./Datasets/clean_test_split/1840/book_12.txt\n",
      "read raw data <- ./Datasets/raw_test_split/1840/book_12.txt\n",
      "write clean data -> ./Datasets/clean_test_split/1840/book_12.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 22\n",
      "read raw data: ./Datasets/raw_test_split/1840/book_04.txt -> clean data -> write clean data: ./Datasets/clean_test_split/1840/book_04.txt\n",
      "read raw data <- ./Datasets/raw_test_split/1840/book_04.txt\n",
      "write clean data -> ./Datasets/clean_test_split/1840/book_04.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 23\n",
      "read raw data: ./Datasets/raw_test_split/1840/book_09.txt -> clean data -> write clean data: ./Datasets/clean_test_split/1840/book_09.txt\n",
      "read raw data <- ./Datasets/raw_test_split/1840/book_09.txt\n",
      "write clean data -> ./Datasets/clean_test_split/1840/book_09.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "clean decade path: ./Datasets/clean_test_split/1850\n",
      "raw decade path: ./Datasets/raw_test_split/1850\n",
      "books processed: 24\n",
      "read raw data: ./Datasets/raw_test_split/1850/book_01.txt -> clean data -> write clean data: ./Datasets/clean_test_split/1850/book_01.txt\n",
      "read raw data <- ./Datasets/raw_test_split/1850/book_01.txt\n",
      "write clean data -> ./Datasets/clean_test_split/1850/book_01.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 25\n",
      "read raw data: ./Datasets/raw_test_split/1850/book_13.txt -> clean data -> write clean data: ./Datasets/clean_test_split/1850/book_13.txt\n",
      "read raw data <- ./Datasets/raw_test_split/1850/book_13.txt\n",
      "write clean data -> ./Datasets/clean_test_split/1850/book_13.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 26\n",
      "read raw data: ./Datasets/raw_test_split/1850/book_04.txt -> clean data -> write clean data: ./Datasets/clean_test_split/1850/book_04.txt\n",
      "read raw data <- ./Datasets/raw_test_split/1850/book_04.txt\n",
      "write clean data -> ./Datasets/clean_test_split/1850/book_04.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "clean decade path: ./Datasets/clean_test_split/1860\n",
      "raw decade path: ./Datasets/raw_test_split/1860\n",
      "books processed: 27\n",
      "read raw data: ./Datasets/raw_test_split/1860/book_07.txt -> clean data -> write clean data: ./Datasets/clean_test_split/1860/book_07.txt\n",
      "read raw data <- ./Datasets/raw_test_split/1860/book_07.txt\n",
      "write clean data -> ./Datasets/clean_test_split/1860/book_07.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 28\n",
      "read raw data: ./Datasets/raw_test_split/1860/book_11.txt -> clean data -> write clean data: ./Datasets/clean_test_split/1860/book_11.txt\n",
      "read raw data <- ./Datasets/raw_test_split/1860/book_11.txt\n",
      "write clean data -> ./Datasets/clean_test_split/1860/book_11.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 29\n",
      "read raw data: ./Datasets/raw_test_split/1860/book_08.txt -> clean data -> write clean data: ./Datasets/clean_test_split/1860/book_08.txt\n",
      "read raw data <- ./Datasets/raw_test_split/1860/book_08.txt\n",
      "write clean data -> ./Datasets/clean_test_split/1860/book_08.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "clean decade path: ./Datasets/clean_test_split/1870\n",
      "raw decade path: ./Datasets/raw_test_split/1870\n",
      "books processed: 30\n",
      "read raw data: ./Datasets/raw_test_split/1870/book_06.txt -> clean data -> write clean data: ./Datasets/clean_test_split/1870/book_06.txt\n",
      "read raw data <- ./Datasets/raw_test_split/1870/book_06.txt\n",
      "write clean data -> ./Datasets/clean_test_split/1870/book_06.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 31\n",
      "read raw data: ./Datasets/raw_test_split/1870/book_07.txt -> clean data -> write clean data: ./Datasets/clean_test_split/1870/book_07.txt\n",
      "read raw data <- ./Datasets/raw_test_split/1870/book_07.txt\n",
      "write clean data -> ./Datasets/clean_test_split/1870/book_07.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 32\n",
      "read raw data: ./Datasets/raw_test_split/1870/book_10.txt -> clean data -> write clean data: ./Datasets/clean_test_split/1870/book_10.txt\n",
      "read raw data <- ./Datasets/raw_test_split/1870/book_10.txt\n",
      "write clean data -> ./Datasets/clean_test_split/1870/book_10.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "clean decade path: ./Datasets/clean_test_split/1880\n",
      "raw decade path: ./Datasets/raw_test_split/1880\n",
      "books processed: 33\n",
      "read raw data: ./Datasets/raw_test_split/1880/book_03.txt -> clean data -> write clean data: ./Datasets/clean_test_split/1880/book_03.txt\n",
      "read raw data <- ./Datasets/raw_test_split/1880/book_03.txt\n",
      "write clean data -> ./Datasets/clean_test_split/1880/book_03.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 34\n",
      "read raw data: ./Datasets/raw_test_split/1880/book_07.txt -> clean data -> write clean data: ./Datasets/clean_test_split/1880/book_07.txt\n",
      "read raw data <- ./Datasets/raw_test_split/1880/book_07.txt\n",
      "write clean data -> ./Datasets/clean_test_split/1880/book_07.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 35\n",
      "read raw data: ./Datasets/raw_test_split/1880/book_11.txt -> clean data -> write clean data: ./Datasets/clean_test_split/1880/book_11.txt\n",
      "read raw data <- ./Datasets/raw_test_split/1880/book_11.txt\n",
      "write clean data -> ./Datasets/clean_test_split/1880/book_11.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "clean decade path: ./Datasets/clean_test_split/1890\n",
      "raw decade path: ./Datasets/raw_test_split/1890\n",
      "books processed: 36\n",
      "read raw data: ./Datasets/raw_test_split/1890/book_02.txt -> clean data -> write clean data: ./Datasets/clean_test_split/1890/book_02.txt\n",
      "read raw data <- ./Datasets/raw_test_split/1890/book_02.txt\n",
      "write clean data -> ./Datasets/clean_test_split/1890/book_02.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 37\n",
      "read raw data: ./Datasets/raw_test_split/1890/book_11.txt -> clean data -> write clean data: ./Datasets/clean_test_split/1890/book_11.txt\n",
      "read raw data <- ./Datasets/raw_test_split/1890/book_11.txt\n",
      "write clean data -> ./Datasets/clean_test_split/1890/book_11.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n",
      "books processed: 38\n",
      "read raw data: ./Datasets/raw_test_split/1890/book_09.txt -> clean data -> write clean data: ./Datasets/clean_test_split/1890/book_09.txt\n",
      "read raw data <- ./Datasets/raw_test_split/1890/book_09.txt\n",
      "write clean data -> ./Datasets/clean_test_split/1890/book_09.txt\n",
      "wrote cleaned data successfully!!!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clean_stratified_split(raw_test_split_path, clean_test_split_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05070628",
   "metadata": {},
   "source": [
    "##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306beaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function creates paragraphs using the ideas mentioned in the paper Deep Learning for Period Classification of Historical\n",
    "Texts\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def create_paragraphs(text, min_words=10, max_words=210):\n",
    "    words = text.split()\n",
    "\n",
    "    paragraphs = []\n",
    "    start = 0\n",
    "    while start < len(words):\n",
    "        end = min(start + max_words, len(words))\n",
    "        paragraph_words = words[start:end]\n",
    "        if len(paragraph_words) >= min_words:\n",
    "            paragraph_text = \" \".join(paragraph_words)\n",
    "            paragraphs.append(paragraph_text)\n",
    "\n",
    "        start = end\n",
    "\n",
    "    return paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a1c8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_paragraph_data(clean_split_path, raw_data_path):\n",
    "    years = sorted(os.listdir(clean_split_path))\n",
    "    print(f\"years in sorted order: {years}\")\n",
    "    # print(f\"dataset path: {os.listdir(clean_train_split_path)}\")\n",
    "    book_titles = get_book_titles(raw_data_path)\n",
    "    paragraph_data = []\n",
    "    total_books = 0\n",
    "\n",
    "    # all the years\n",
    "    for decade in years:\n",
    "        print(f\"process decade: {decade}\")\n",
    "        decade_path = f\"{clean_split_path}/{decade}\"\n",
    "        print(f\"decade_path: {decade_path}\")\n",
    "        decade_titles = book_titles[int(decade)]\n",
    "        print(f\"number of book titles in decade: {len(decade_titles)}\")\n",
    "\n",
    "        if os.path.exists(decade_path):\n",
    "            text_files = sorted(\n",
    "                [f for f in os.listdir(decade_path) if f.endswith(\".txt\")]\n",
    "            )\n",
    "            for index, text_filename in enumerate(text_files):\n",
    "                print(f\"current book: {index + 1}\")\n",
    "                total_books += 1\n",
    "                print(f\"book filename: {text_filename}\")\n",
    "                text_file_number = int(re.findall(r\"\\d+\", text_filename)[0])\n",
    "                print(f\"book number: {text_file_number}\")\n",
    "                book_title = decade_titles[text_file_number - 1]\n",
    "                text_filepath = os.path.join(decade_path, text_filename)\n",
    "                with open(text_filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "                    clean_book_data = f.read()\n",
    "                    print(f\"succesfully read book!!!\")\n",
    "                book_paragraphs = create_paragraphs(clean_book_data)\n",
    "                print(f\"number of paragraphs created: {len(book_paragraphs)}\")\n",
    "                paragraph_length = len(book_paragraphs[0].split())\n",
    "                print(f\"length of a paragraph: {paragraph_length}\")\n",
    "\n",
    "                paragraph_info = {\n",
    "                    \"paragraphs\": book_paragraphs,\n",
    "                    \"book_title\": book_title,\n",
    "                    \"decade\": decade,\n",
    "                    \"filepath\": text_filepath,\n",
    "                    \"book_id\": f\"{decade}_{book_title[:20].replace(' ', '_')}\",\n",
    "                }\n",
    "                paragraph_data.append(paragraph_info)\n",
    "\n",
    "        print(f\"total number of books processed in decade {decade} -> {total_books}\")\n",
    "        print()\n",
    "\n",
    "    print(f\"total number of books processed: {total_books}\")\n",
    "    return paragraph_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "99707082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "years in sorted order: ['1770', '1780', '1790', '1800', '1810', '1820', '1830', '1840', '1850', '1860', '1870', '1880', '1890']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "process decade: 1770\n",
      "decade_path: ./Datasets/clean_train_split/1770\n",
      "number of book titles in decade: 12\n",
      "current book: 1\n",
      "book filename: book_03.txt\n",
      "book number: 3\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 138\n",
      "length of a paragraph: 210\n",
      "current book: 2\n",
      "book filename: book_04.txt\n",
      "book number: 4\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 707\n",
      "length of a paragraph: 210\n",
      "current book: 3\n",
      "book filename: book_05.txt\n",
      "book number: 5\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 738\n",
      "length of a paragraph: 210\n",
      "current book: 4\n",
      "book filename: book_06.txt\n",
      "book number: 6\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 135\n",
      "length of a paragraph: 210\n",
      "current book: 5\n",
      "book filename: book_07.txt\n",
      "book number: 7\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 862\n",
      "length of a paragraph: 210\n",
      "current book: 6\n",
      "book filename: book_08.txt\n",
      "book number: 8\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 7605\n",
      "length of a paragraph: 210\n",
      "current book: 7\n",
      "book filename: book_09.txt\n",
      "book number: 9\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 270\n",
      "length of a paragraph: 210\n",
      "current book: 8\n",
      "book filename: book_10.txt\n",
      "book number: 10\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 105\n",
      "length of a paragraph: 210\n",
      "current book: 9\n",
      "book filename: book_12.txt\n",
      "book number: 12\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 19\n",
      "length of a paragraph: 210\n",
      "total number of books processed in decade 1770 -> 9\n",
      "\n",
      "process decade: 1780\n",
      "decade_path: ./Datasets/clean_train_split/1780\n",
      "number of book titles in decade: 12\n",
      "current book: 1\n",
      "book filename: book_03.txt\n",
      "book number: 3\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 1003\n",
      "length of a paragraph: 210\n",
      "current book: 2\n",
      "book filename: book_04.txt\n",
      "book number: 4\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 202\n",
      "length of a paragraph: 210\n",
      "current book: 3\n",
      "book filename: book_05.txt\n",
      "book number: 5\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 514\n",
      "length of a paragraph: 210\n",
      "current book: 4\n",
      "book filename: book_06.txt\n",
      "book number: 6\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 996\n",
      "length of a paragraph: 210\n",
      "current book: 5\n",
      "book filename: book_07.txt\n",
      "book number: 7\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 223\n",
      "length of a paragraph: 210\n",
      "current book: 6\n",
      "book filename: book_08.txt\n",
      "book number: 8\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 916\n",
      "length of a paragraph: 210\n",
      "current book: 7\n",
      "book filename: book_09.txt\n",
      "book number: 9\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 379\n",
      "length of a paragraph: 210\n",
      "current book: 8\n",
      "book filename: book_10.txt\n",
      "book number: 10\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 407\n",
      "length of a paragraph: 210\n",
      "current book: 9\n",
      "book filename: book_11.txt\n",
      "book number: 11\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 407\n",
      "length of a paragraph: 210\n",
      "total number of books processed in decade 1780 -> 18\n",
      "\n",
      "process decade: 1790\n",
      "decade_path: ./Datasets/clean_train_split/1790\n",
      "number of book titles in decade: 11\n",
      "current book: 1\n",
      "book filename: book_01.txt\n",
      "book number: 1\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 445\n",
      "length of a paragraph: 210\n",
      "current book: 2\n",
      "book filename: book_02.txt\n",
      "book number: 2\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 412\n",
      "length of a paragraph: 210\n",
      "current book: 3\n",
      "book filename: book_03.txt\n",
      "book number: 3\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 1383\n",
      "length of a paragraph: 210\n",
      "current book: 4\n",
      "book filename: book_06.txt\n",
      "book number: 6\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 345\n",
      "length of a paragraph: 210\n",
      "current book: 5\n",
      "book filename: book_07.txt\n",
      "book number: 7\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 240\n",
      "length of a paragraph: 210\n",
      "current book: 6\n",
      "book filename: book_09.txt\n",
      "book number: 9\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 103\n",
      "length of a paragraph: 210\n",
      "current book: 7\n",
      "book filename: book_10.txt\n",
      "book number: 10\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 1702\n",
      "length of a paragraph: 210\n",
      "current book: 8\n",
      "book filename: book_11.txt\n",
      "book number: 11\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 1035\n",
      "length of a paragraph: 210\n",
      "total number of books processed in decade 1790 -> 26\n",
      "\n",
      "process decade: 1800\n",
      "decade_path: ./Datasets/clean_train_split/1800\n",
      "number of book titles in decade: 10\n",
      "current book: 1\n",
      "book filename: book_01.txt\n",
      "book number: 1\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 215\n",
      "length of a paragraph: 210\n",
      "current book: 2\n",
      "book filename: book_02.txt\n",
      "book number: 2\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 885\n",
      "length of a paragraph: 210\n",
      "current book: 3\n",
      "book filename: book_03.txt\n",
      "book number: 3\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 413\n",
      "length of a paragraph: 210\n",
      "current book: 4\n",
      "book filename: book_05.txt\n",
      "book number: 5\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 490\n",
      "length of a paragraph: 210\n",
      "current book: 5\n",
      "book filename: book_07.txt\n",
      "book number: 7\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 211\n",
      "length of a paragraph: 210\n",
      "current book: 6\n",
      "book filename: book_08.txt\n",
      "book number: 8\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 305\n",
      "length of a paragraph: 210\n",
      "current book: 7\n",
      "book filename: book_09.txt\n",
      "book number: 9\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 648\n",
      "length of a paragraph: 210\n",
      "current book: 8\n",
      "book filename: book_10.txt\n",
      "book number: 10\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 653\n",
      "length of a paragraph: 210\n",
      "total number of books processed in decade 1800 -> 34\n",
      "\n",
      "process decade: 1810\n",
      "decade_path: ./Datasets/clean_train_split/1810\n",
      "number of book titles in decade: 15\n",
      "current book: 1\n",
      "book filename: book_02.txt\n",
      "book number: 2\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 566\n",
      "length of a paragraph: 210\n",
      "current book: 2\n",
      "book filename: book_03.txt\n",
      "book number: 3\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 607\n",
      "length of a paragraph: 210\n",
      "current book: 3\n",
      "book filename: book_04.txt\n",
      "book number: 4\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 761\n",
      "length of a paragraph: 210\n",
      "current book: 4\n",
      "book filename: book_05.txt\n",
      "book number: 5\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 751\n",
      "length of a paragraph: 210\n",
      "current book: 5\n",
      "book filename: book_06.txt\n",
      "book number: 6\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 397\n",
      "length of a paragraph: 210\n",
      "current book: 6\n",
      "book filename: book_07.txt\n",
      "book number: 7\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 368\n",
      "length of a paragraph: 210\n",
      "current book: 7\n",
      "book filename: book_08.txt\n",
      "book number: 8\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 358\n",
      "length of a paragraph: 210\n",
      "current book: 8\n",
      "book filename: book_09.txt\n",
      "book number: 9\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 916\n",
      "length of a paragraph: 210\n",
      "current book: 9\n",
      "book filename: book_10.txt\n",
      "book number: 10\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 913\n",
      "length of a paragraph: 210\n",
      "current book: 10\n",
      "book filename: book_11.txt\n",
      "book number: 11\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 859\n",
      "length of a paragraph: 210\n",
      "current book: 11\n",
      "book filename: book_14.txt\n",
      "book number: 14\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 460\n",
      "length of a paragraph: 210\n",
      "current book: 12\n",
      "book filename: book_15.txt\n",
      "book number: 15\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 529\n",
      "length of a paragraph: 210\n",
      "total number of books processed in decade 1810 -> 46\n",
      "\n",
      "process decade: 1820\n",
      "decade_path: ./Datasets/clean_train_split/1820\n",
      "number of book titles in decade: 14\n",
      "current book: 1\n",
      "book filename: book_03.txt\n",
      "book number: 3\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 798\n",
      "length of a paragraph: 210\n",
      "current book: 2\n",
      "book filename: book_04.txt\n",
      "book number: 4\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 745\n",
      "length of a paragraph: 210\n",
      "current book: 3\n",
      "book filename: book_05.txt\n",
      "book number: 5\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 791\n",
      "length of a paragraph: 210\n",
      "current book: 4\n",
      "book filename: book_06.txt\n",
      "book number: 6\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 876\n",
      "length of a paragraph: 210\n",
      "current book: 5\n",
      "book filename: book_07.txt\n",
      "book number: 7\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 887\n",
      "length of a paragraph: 210\n",
      "current book: 6\n",
      "book filename: book_08.txt\n",
      "book number: 8\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 613\n",
      "length of a paragraph: 210\n",
      "current book: 7\n",
      "book filename: book_09.txt\n",
      "book number: 9\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 59\n",
      "length of a paragraph: 210\n",
      "current book: 8\n",
      "book filename: book_10.txt\n",
      "book number: 10\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 40\n",
      "length of a paragraph: 210\n",
      "current book: 9\n",
      "book filename: book_11.txt\n",
      "book number: 11\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 612\n",
      "length of a paragraph: 210\n",
      "current book: 10\n",
      "book filename: book_13.txt\n",
      "book number: 13\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 236\n",
      "length of a paragraph: 210\n",
      "current book: 11\n",
      "book filename: book_14.txt\n",
      "book number: 14\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 832\n",
      "length of a paragraph: 210\n",
      "total number of books processed in decade 1820 -> 57\n",
      "\n",
      "process decade: 1830\n",
      "decade_path: ./Datasets/clean_train_split/1830\n",
      "number of book titles in decade: 12\n",
      "current book: 1\n",
      "book filename: book_01.txt\n",
      "book number: 1\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 1429\n",
      "length of a paragraph: 210\n",
      "current book: 2\n",
      "book filename: book_02.txt\n",
      "book number: 2\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 753\n",
      "length of a paragraph: 210\n",
      "current book: 3\n",
      "book filename: book_04.txt\n",
      "book number: 4\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 1442\n",
      "length of a paragraph: 210\n",
      "current book: 4\n",
      "book filename: book_05.txt\n",
      "book number: 5\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 857\n",
      "length of a paragraph: 210\n",
      "current book: 5\n",
      "book filename: book_07.txt\n",
      "book number: 7\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 879\n",
      "length of a paragraph: 210\n",
      "current book: 6\n",
      "book filename: book_08.txt\n",
      "book number: 8\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 488\n",
      "length of a paragraph: 210\n",
      "current book: 7\n",
      "book filename: book_09.txt\n",
      "book number: 9\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 121\n",
      "length of a paragraph: 210\n",
      "current book: 8\n",
      "book filename: book_10.txt\n",
      "book number: 10\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 544\n",
      "length of a paragraph: 210\n",
      "current book: 9\n",
      "book filename: book_12.txt\n",
      "book number: 12\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 668\n",
      "length of a paragraph: 210\n",
      "total number of books processed in decade 1830 -> 66\n",
      "\n",
      "process decade: 1840\n",
      "decade_path: ./Datasets/clean_train_split/1840\n",
      "number of book titles in decade: 13\n",
      "current book: 1\n",
      "book filename: book_01.txt\n",
      "book number: 1\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 883\n",
      "length of a paragraph: 210\n",
      "current book: 2\n",
      "book filename: book_02.txt\n",
      "book number: 2\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 553\n",
      "length of a paragraph: 210\n",
      "current book: 3\n",
      "book filename: book_03.txt\n",
      "book number: 3\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 323\n",
      "length of a paragraph: 210\n",
      "current book: 4\n",
      "book filename: book_05.txt\n",
      "book number: 5\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 140\n",
      "length of a paragraph: 210\n",
      "current book: 5\n",
      "book filename: book_06.txt\n",
      "book number: 6\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 1029\n",
      "length of a paragraph: 210\n",
      "current book: 6\n",
      "book filename: book_07.txt\n",
      "book number: 7\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 1604\n",
      "length of a paragraph: 210\n",
      "current book: 7\n",
      "book filename: book_08.txt\n",
      "book number: 8\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 1440\n",
      "length of a paragraph: 210\n",
      "current book: 8\n",
      "book filename: book_10.txt\n",
      "book number: 10\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 1093\n",
      "length of a paragraph: 210\n",
      "current book: 9\n",
      "book filename: book_11.txt\n",
      "book number: 11\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 161\n",
      "length of a paragraph: 210\n",
      "current book: 10\n",
      "book filename: book_13.txt\n",
      "book number: 13\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 302\n",
      "length of a paragraph: 210\n",
      "total number of books processed in decade 1840 -> 76\n",
      "\n",
      "process decade: 1850\n",
      "decade_path: ./Datasets/clean_train_split/1850\n",
      "number of book titles in decade: 13\n",
      "current book: 1\n",
      "book filename: book_02.txt\n",
      "book number: 2\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 500\n",
      "length of a paragraph: 210\n",
      "current book: 2\n",
      "book filename: book_03.txt\n",
      "book number: 3\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 1014\n",
      "length of a paragraph: 210\n",
      "current book: 3\n",
      "book filename: book_05.txt\n",
      "book number: 5\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 1684\n",
      "length of a paragraph: 210\n",
      "current book: 4\n",
      "book filename: book_06.txt\n",
      "book number: 6\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 648\n",
      "length of a paragraph: 210\n",
      "current book: 5\n",
      "book filename: book_07.txt\n",
      "book number: 7\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 362\n",
      "length of a paragraph: 210\n",
      "current book: 6\n",
      "book filename: book_08.txt\n",
      "book number: 8\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 447\n",
      "length of a paragraph: 210\n",
      "current book: 7\n",
      "book filename: book_09.txt\n",
      "book number: 9\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 552\n",
      "length of a paragraph: 210\n",
      "current book: 8\n",
      "book filename: book_10.txt\n",
      "book number: 10\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 1727\n",
      "length of a paragraph: 210\n",
      "current book: 9\n",
      "book filename: book_11.txt\n",
      "book number: 11\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 862\n",
      "length of a paragraph: 210\n",
      "current book: 10\n",
      "book filename: book_12.txt\n",
      "book number: 12\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 580\n",
      "length of a paragraph: 210\n",
      "total number of books processed in decade 1850 -> 86\n",
      "\n",
      "process decade: 1860\n",
      "decade_path: ./Datasets/clean_train_split/1860\n",
      "number of book titles in decade: 12\n",
      "current book: 1\n",
      "book filename: book_01.txt\n",
      "book number: 1\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 1166\n",
      "length of a paragraph: 210\n",
      "current book: 2\n",
      "book filename: book_02.txt\n",
      "book number: 2\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 879\n",
      "length of a paragraph: 210\n",
      "current book: 3\n",
      "book filename: book_03.txt\n",
      "book number: 3\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 338\n",
      "length of a paragraph: 210\n",
      "current book: 4\n",
      "book filename: book_04.txt\n",
      "book number: 4\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 984\n",
      "length of a paragraph: 210\n",
      "current book: 5\n",
      "book filename: book_05.txt\n",
      "book number: 5\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 864\n",
      "length of a paragraph: 210\n",
      "current book: 6\n",
      "book filename: book_06.txt\n",
      "book number: 6\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 127\n",
      "length of a paragraph: 210\n",
      "current book: 7\n",
      "book filename: book_09.txt\n",
      "book number: 9\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 436\n",
      "length of a paragraph: 210\n",
      "current book: 8\n",
      "book filename: book_10.txt\n",
      "book number: 10\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 499\n",
      "length of a paragraph: 210\n",
      "current book: 9\n",
      "book filename: book_12.txt\n",
      "book number: 12\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 2693\n",
      "length of a paragraph: 210\n",
      "total number of books processed in decade 1860 -> 95\n",
      "\n",
      "process decade: 1870\n",
      "decade_path: ./Datasets/clean_train_split/1870\n",
      "number of book titles in decade: 12\n",
      "current book: 1\n",
      "book filename: book_01.txt\n",
      "book number: 1\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 456\n",
      "length of a paragraph: 210\n",
      "current book: 2\n",
      "book filename: book_02.txt\n",
      "book number: 2\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 142\n",
      "length of a paragraph: 210\n",
      "current book: 3\n",
      "book filename: book_03.txt\n",
      "book number: 3\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 621\n",
      "length of a paragraph: 210\n",
      "current book: 4\n",
      "book filename: book_04.txt\n",
      "book number: 4\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 653\n",
      "length of a paragraph: 210\n",
      "current book: 5\n",
      "book filename: book_05.txt\n",
      "book number: 5\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 1671\n",
      "length of a paragraph: 210\n",
      "current book: 6\n",
      "book filename: book_08.txt\n",
      "book number: 8\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 677\n",
      "length of a paragraph: 210\n",
      "current book: 7\n",
      "book filename: book_09.txt\n",
      "book number: 9\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 1666\n",
      "length of a paragraph: 210\n",
      "current book: 8\n",
      "book filename: book_11.txt\n",
      "book number: 11\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 628\n",
      "length of a paragraph: 210\n",
      "current book: 9\n",
      "book filename: book_12.txt\n",
      "book number: 12\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 1151\n",
      "length of a paragraph: 210\n",
      "total number of books processed in decade 1870 -> 104\n",
      "\n",
      "process decade: 1880\n",
      "decade_path: ./Datasets/clean_train_split/1880\n",
      "number of book titles in decade: 12\n",
      "current book: 1\n",
      "book filename: book_01.txt\n",
      "book number: 1\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 304\n",
      "length of a paragraph: 210\n",
      "current book: 2\n",
      "book filename: book_02.txt\n",
      "book number: 2\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 557\n",
      "length of a paragraph: 210\n",
      "current book: 3\n",
      "book filename: book_04.txt\n",
      "book number: 4\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 529\n",
      "length of a paragraph: 210\n",
      "current book: 4\n",
      "book filename: book_05.txt\n",
      "book number: 5\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 613\n",
      "length of a paragraph: 210\n",
      "current book: 5\n",
      "book filename: book_06.txt\n",
      "book number: 6\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 122\n",
      "length of a paragraph: 210\n",
      "current book: 6\n",
      "book filename: book_08.txt\n",
      "book number: 8\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 390\n",
      "length of a paragraph: 210\n",
      "current book: 7\n",
      "book filename: book_09.txt\n",
      "book number: 9\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 207\n",
      "length of a paragraph: 210\n",
      "current book: 8\n",
      "book filename: book_10.txt\n",
      "book number: 10\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 561\n",
      "length of a paragraph: 210\n",
      "current book: 9\n",
      "book filename: book_12.txt\n",
      "book number: 12\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 415\n",
      "length of a paragraph: 210\n",
      "total number of books processed in decade 1880 -> 113\n",
      "\n",
      "process decade: 1890\n",
      "decade_path: ./Datasets/clean_train_split/1890\n",
      "number of book titles in decade: 12\n",
      "current book: 1\n",
      "book filename: book_01.txt\n",
      "book number: 1\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 377\n",
      "length of a paragraph: 210\n",
      "current book: 2\n",
      "book filename: book_03.txt\n",
      "book number: 3\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 715\n",
      "length of a paragraph: 210\n",
      "current book: 3\n",
      "book filename: book_04.txt\n",
      "book number: 4\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 498\n",
      "length of a paragraph: 210\n",
      "current book: 4\n",
      "book filename: book_05.txt\n",
      "book number: 5\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 95\n",
      "length of a paragraph: 210\n",
      "current book: 5\n",
      "book filename: book_06.txt\n",
      "book number: 6\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 243\n",
      "length of a paragraph: 210\n",
      "current book: 6\n",
      "book filename: book_07.txt\n",
      "book number: 7\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 155\n",
      "length of a paragraph: 210\n",
      "current book: 7\n",
      "book filename: book_08.txt\n",
      "book number: 8\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 99\n",
      "length of a paragraph: 210\n",
      "current book: 8\n",
      "book filename: book_10.txt\n",
      "book number: 10\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 769\n",
      "length of a paragraph: 210\n",
      "current book: 9\n",
      "book filename: book_12.txt\n",
      "book number: 12\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 390\n",
      "length of a paragraph: 210\n",
      "total number of books processed in decade 1890 -> 122\n",
      "\n",
      "total number of books processed: 122\n"
     ]
    }
   ],
   "source": [
    "paragraph_train_data = create_paragraph_data(clean_train_split_path, raw_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "093f5527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "years in sorted order: ['1770', '1780', '1790', '1800', '1810', '1820', '1830', '1840', '1850', '1860', '1870', '1880', '1890']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "process decade: 1770\n",
      "decade_path: ./Datasets/clean_test_split/1770\n",
      "number of book titles in decade: 12\n",
      "current book: 1\n",
      "book filename: book_01.txt\n",
      "book number: 1\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 1814\n",
      "length of a paragraph: 210\n",
      "current book: 2\n",
      "book filename: book_02.txt\n",
      "book number: 2\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 109\n",
      "length of a paragraph: 210\n",
      "current book: 3\n",
      "book filename: book_11.txt\n",
      "book number: 11\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 177\n",
      "length of a paragraph: 210\n",
      "total number of books processed in decade 1770 -> 3\n",
      "\n",
      "process decade: 1780\n",
      "decade_path: ./Datasets/clean_test_split/1780\n",
      "number of book titles in decade: 12\n",
      "current book: 1\n",
      "book filename: book_01.txt\n",
      "book number: 1\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 27\n",
      "length of a paragraph: 210\n",
      "current book: 2\n",
      "book filename: book_02.txt\n",
      "book number: 2\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 594\n",
      "length of a paragraph: 210\n",
      "current book: 3\n",
      "book filename: book_12.txt\n",
      "book number: 12\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 189\n",
      "length of a paragraph: 210\n",
      "total number of books processed in decade 1780 -> 6\n",
      "\n",
      "process decade: 1790\n",
      "decade_path: ./Datasets/clean_test_split/1790\n",
      "number of book titles in decade: 11\n",
      "current book: 1\n",
      "book filename: book_04.txt\n",
      "book number: 4\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 654\n",
      "length of a paragraph: 210\n",
      "current book: 2\n",
      "book filename: book_05.txt\n",
      "book number: 5\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 259\n",
      "length of a paragraph: 210\n",
      "current book: 3\n",
      "book filename: book_08.txt\n",
      "book number: 8\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 215\n",
      "length of a paragraph: 210\n",
      "total number of books processed in decade 1790 -> 9\n",
      "\n",
      "process decade: 1800\n",
      "decade_path: ./Datasets/clean_test_split/1800\n",
      "number of book titles in decade: 10\n",
      "current book: 1\n",
      "book filename: book_04.txt\n",
      "book number: 4\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 435\n",
      "length of a paragraph: 210\n",
      "current book: 2\n",
      "book filename: book_06.txt\n",
      "book number: 6\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 487\n",
      "length of a paragraph: 210\n",
      "total number of books processed in decade 1800 -> 11\n",
      "\n",
      "process decade: 1810\n",
      "decade_path: ./Datasets/clean_test_split/1810\n",
      "number of book titles in decade: 15\n",
      "current book: 1\n",
      "book filename: book_01.txt\n",
      "book number: 1\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 374\n",
      "length of a paragraph: 210\n",
      "current book: 2\n",
      "book filename: book_12.txt\n",
      "book number: 12\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 821\n",
      "length of a paragraph: 210\n",
      "current book: 3\n",
      "book filename: book_13.txt\n",
      "book number: 13\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 274\n",
      "length of a paragraph: 210\n",
      "total number of books processed in decade 1810 -> 14\n",
      "\n",
      "process decade: 1820\n",
      "decade_path: ./Datasets/clean_test_split/1820\n",
      "number of book titles in decade: 14\n",
      "current book: 1\n",
      "book filename: book_01.txt\n",
      "book number: 1\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 707\n",
      "length of a paragraph: 210\n",
      "current book: 2\n",
      "book filename: book_02.txt\n",
      "book number: 2\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 819\n",
      "length of a paragraph: 210\n",
      "current book: 3\n",
      "book filename: book_12.txt\n",
      "book number: 12\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 936\n",
      "length of a paragraph: 210\n",
      "total number of books processed in decade 1820 -> 17\n",
      "\n",
      "process decade: 1830\n",
      "decade_path: ./Datasets/clean_test_split/1830\n",
      "number of book titles in decade: 12\n",
      "current book: 1\n",
      "book filename: book_03.txt\n",
      "book number: 3\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 382\n",
      "length of a paragraph: 210\n",
      "current book: 2\n",
      "book filename: book_06.txt\n",
      "book number: 6\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 755\n",
      "length of a paragraph: 210\n",
      "current book: 3\n",
      "book filename: book_11.txt\n",
      "book number: 11\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 747\n",
      "length of a paragraph: 210\n",
      "total number of books processed in decade 1830 -> 20\n",
      "\n",
      "process decade: 1840\n",
      "decade_path: ./Datasets/clean_test_split/1840\n",
      "number of book titles in decade: 13\n",
      "current book: 1\n",
      "book filename: book_04.txt\n",
      "book number: 4\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 804\n",
      "length of a paragraph: 210\n",
      "current book: 2\n",
      "book filename: book_09.txt\n",
      "book number: 9\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 2196\n",
      "length of a paragraph: 210\n",
      "current book: 3\n",
      "book filename: book_12.txt\n",
      "book number: 12\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 776\n",
      "length of a paragraph: 210\n",
      "total number of books processed in decade 1840 -> 23\n",
      "\n",
      "process decade: 1850\n",
      "decade_path: ./Datasets/clean_test_split/1850\n",
      "number of book titles in decade: 13\n",
      "current book: 1\n",
      "book filename: book_01.txt\n",
      "book number: 1\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 302\n",
      "length of a paragraph: 210\n",
      "current book: 2\n",
      "book filename: book_04.txt\n",
      "book number: 4\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 862\n",
      "length of a paragraph: 210\n",
      "current book: 3\n",
      "book filename: book_13.txt\n",
      "book number: 13\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 1020\n",
      "length of a paragraph: 210\n",
      "total number of books processed in decade 1850 -> 26\n",
      "\n",
      "process decade: 1860\n",
      "decade_path: ./Datasets/clean_test_split/1860\n",
      "number of book titles in decade: 12\n",
      "current book: 1\n",
      "book filename: book_07.txt\n",
      "book number: 7\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 929\n",
      "length of a paragraph: 210\n",
      "current book: 2\n",
      "book filename: book_08.txt\n",
      "book number: 8\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 917\n",
      "length of a paragraph: 210\n",
      "current book: 3\n",
      "book filename: book_11.txt\n",
      "book number: 11\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 970\n",
      "length of a paragraph: 210\n",
      "total number of books processed in decade 1860 -> 29\n",
      "\n",
      "process decade: 1870\n",
      "decade_path: ./Datasets/clean_test_split/1870\n",
      "number of book titles in decade: 12\n",
      "current book: 1\n",
      "book filename: book_06.txt\n",
      "book number: 6\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 1471\n",
      "length of a paragraph: 210\n",
      "current book: 2\n",
      "book filename: book_07.txt\n",
      "book number: 7\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 338\n",
      "length of a paragraph: 210\n",
      "current book: 3\n",
      "book filename: book_10.txt\n",
      "book number: 10\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 1671\n",
      "length of a paragraph: 210\n",
      "total number of books processed in decade 1870 -> 32\n",
      "\n",
      "process decade: 1880\n",
      "decade_path: ./Datasets/clean_test_split/1880\n",
      "number of book titles in decade: 12\n",
      "current book: 1\n",
      "book filename: book_03.txt\n",
      "book number: 3\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 327\n",
      "length of a paragraph: 210\n",
      "current book: 2\n",
      "book filename: book_07.txt\n",
      "book number: 7\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 549\n",
      "length of a paragraph: 210\n",
      "current book: 3\n",
      "book filename: book_11.txt\n",
      "book number: 11\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 943\n",
      "length of a paragraph: 210\n",
      "total number of books processed in decade 1880 -> 35\n",
      "\n",
      "process decade: 1890\n",
      "decade_path: ./Datasets/clean_test_split/1890\n",
      "number of book titles in decade: 12\n",
      "current book: 1\n",
      "book filename: book_02.txt\n",
      "book number: 2\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 206\n",
      "length of a paragraph: 210\n",
      "current book: 2\n",
      "book filename: book_09.txt\n",
      "book number: 9\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 251\n",
      "length of a paragraph: 210\n",
      "current book: 3\n",
      "book filename: book_11.txt\n",
      "book number: 11\n",
      "succesfully read book!!!\n",
      "number of paragraphs created: 231\n",
      "length of a paragraph: 210\n",
      "total number of books processed in decade 1890 -> 38\n",
      "\n",
      "total number of books processed: 38\n"
     ]
    }
   ],
   "source": [
    "paragraph_test_data = create_paragraph_data(clean_test_split_path, raw_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc4bab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_data_to_csv(paragraph_data, output_file):\n",
    "    print(f\"write {len(paragraph_data)} -> {output_file}\")\n",
    "\n",
    "    # map decade to label for classification\n",
    "    decades = sorted(set(int(item[\"decade\"]) for item in paragraph_data))\n",
    "    decade_to_label = {decade: idx for idx, decade in enumerate(decades)}\n",
    "\n",
    "    with open(output_file, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        header_fields = [\n",
    "            \"text\",\n",
    "            \"decade\",\n",
    "            \"decade_label\",\n",
    "            \"book_title\",\n",
    "            \"book_id\",\n",
    "            \"paragraph_id\",\n",
    "            \"word_count\",\n",
    "        ]\n",
    "        writer = csv.DictWriter(f, fieldnames=header_fields)\n",
    "\n",
    "        writer.writeheader()\n",
    "        total_paragraphs = 0\n",
    "        total_book_count = 0\n",
    "\n",
    "        for book_index, paragraph_info in enumerate(paragraph_data):\n",
    "            decade = int(paragraph_info[\"decade\"])\n",
    "            decade_label = decade_to_label[decade]\n",
    "            book_title = paragraph_info[\"book_title\"]\n",
    "            book_id = paragraph_info[\"book_id\"]\n",
    "            paragraphs = paragraph_info[\"paragraphs\"]\n",
    "\n",
    "            for index, text in enumerate(paragraphs):\n",
    "                clean_text = text.replace(\"\\n\", \" \").replace(\"\\r\", \" \").strip()\n",
    "                word_count = len(clean_text.split())\n",
    "\n",
    "                # from the paper\n",
    "                if word_count < 10:\n",
    "                    continue\n",
    "\n",
    "                writer.writerow(\n",
    "                    {\n",
    "                        \"text\": clean_text,\n",
    "                        \"decade\": decade,\n",
    "                        \"decade_label\": decade_label,\n",
    "                        \"book_title\": book_title,\n",
    "                        \"book_id\": book_id,\n",
    "                        \"paragraph_id\": f\"{decade}_{book_id}_{index:03d}\",\n",
    "                        \"word_count\": word_count,\n",
    "                    }\n",
    "                )\n",
    "                total_paragraphs += 1\n",
    "\n",
    "            total_book_count += 1\n",
    "            print(f\"processed total books: {book_index + 1}\")\n",
    "\n",
    "    print(\n",
    "        f\"Succesfully wrote {total_paragraphs} paragraphs and processed {total_book_count} books -> {output_file}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b2f4e8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write 122 -> ./Datasets/model_data/train_data.csv\n",
      "processed total books: 1\n",
      "processed total books: 2\n",
      "processed total books: 3\n",
      "processed total books: 4\n",
      "processed total books: 5\n",
      "processed total books: 6\n",
      "processed total books: 7\n",
      "processed total books: 8\n",
      "processed total books: 9\n",
      "processed total books: 10\n",
      "processed total books: 11\n",
      "processed total books: 12\n",
      "processed total books: 13\n",
      "processed total books: 14\n",
      "processed total books: 15\n",
      "processed total books: 16\n",
      "processed total books: 17\n",
      "processed total books: 18\n",
      "processed total books: 19\n",
      "processed total books: 20\n",
      "processed total books: 21\n",
      "processed total books: 22\n",
      "processed total books: 23\n",
      "processed total books: 24\n",
      "processed total books: 25\n",
      "processed total books: 26\n",
      "processed total books: 27\n",
      "processed total books: 28\n",
      "processed total books: 29\n",
      "processed total books: 30\n",
      "processed total books: 31\n",
      "processed total books: 32\n",
      "processed total books: 33\n",
      "processed total books: 34\n",
      "processed total books: 35\n",
      "processed total books: 36\n",
      "processed total books: 37\n",
      "processed total books: 38\n",
      "processed total books: 39\n",
      "processed total books: 40\n",
      "processed total books: 41\n",
      "processed total books: 42\n",
      "processed total books: 43\n",
      "processed total books: 44\n",
      "processed total books: 45\n",
      "processed total books: 46\n",
      "processed total books: 47\n",
      "processed total books: 48\n",
      "processed total books: 49\n",
      "processed total books: 50\n",
      "processed total books: 51\n",
      "processed total books: 52\n",
      "processed total books: 53\n",
      "processed total books: 54\n",
      "processed total books: 55\n",
      "processed total books: 56\n",
      "processed total books: 57\n",
      "processed total books: 58\n",
      "processed total books: 59\n",
      "processed total books: 60\n",
      "processed total books: 61\n",
      "processed total books: 62\n",
      "processed total books: 63\n",
      "processed total books: 64\n",
      "processed total books: 65\n",
      "processed total books: 66\n",
      "processed total books: 67\n",
      "processed total books: 68\n",
      "processed total books: 69\n",
      "processed total books: 70\n",
      "processed total books: 71\n",
      "processed total books: 72\n",
      "processed total books: 73\n",
      "processed total books: 74\n",
      "processed total books: 75\n",
      "processed total books: 76\n",
      "processed total books: 77\n",
      "processed total books: 78\n",
      "processed total books: 79\n",
      "processed total books: 80\n",
      "processed total books: 81\n",
      "processed total books: 82\n",
      "processed total books: 83\n",
      "processed total books: 84\n",
      "processed total books: 85\n",
      "processed total books: 86\n",
      "processed total books: 87\n",
      "processed total books: 88\n",
      "processed total books: 89\n",
      "processed total books: 90\n",
      "processed total books: 91\n",
      "processed total books: 92\n",
      "processed total books: 93\n",
      "processed total books: 94\n",
      "processed total books: 95\n",
      "processed total books: 96\n",
      "processed total books: 97\n",
      "processed total books: 98\n",
      "processed total books: 99\n",
      "processed total books: 100\n",
      "processed total books: 101\n",
      "processed total books: 102\n",
      "processed total books: 103\n",
      "processed total books: 104\n",
      "processed total books: 105\n",
      "processed total books: 106\n",
      "processed total books: 107\n",
      "processed total books: 108\n",
      "processed total books: 109\n",
      "processed total books: 110\n",
      "processed total books: 111\n",
      "processed total books: 112\n",
      "processed total books: 113\n",
      "processed total books: 114\n",
      "processed total books: 115\n",
      "processed total books: 116\n",
      "processed total books: 117\n",
      "processed total books: 118\n",
      "processed total books: 119\n",
      "processed total books: 120\n",
      "processed total books: 121\n",
      "processed total books: 122\n",
      "Succesfully wrote 84860 paragraphs and processed 122 books -> ./Datasets/model_data/train_data.csv\n"
     ]
    }
   ],
   "source": [
    "out_file = os.path.join(model_dataset_path, \"train_data.csv\")\n",
    "write_data_to_csv(paragraph_train_data, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ba23e53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write 38 -> ./Datasets/model_data/test_data.csv\n",
      "processed total books: 1\n",
      "processed total books: 2\n",
      "processed total books: 3\n",
      "processed total books: 4\n",
      "processed total books: 5\n",
      "processed total books: 6\n",
      "processed total books: 7\n",
      "processed total books: 8\n",
      "processed total books: 9\n",
      "processed total books: 10\n",
      "processed total books: 11\n",
      "processed total books: 12\n",
      "processed total books: 13\n",
      "processed total books: 14\n",
      "processed total books: 15\n",
      "processed total books: 16\n",
      "processed total books: 17\n",
      "processed total books: 18\n",
      "processed total books: 19\n",
      "processed total books: 20\n",
      "processed total books: 21\n",
      "processed total books: 22\n",
      "processed total books: 23\n",
      "processed total books: 24\n",
      "processed total books: 25\n",
      "processed total books: 26\n",
      "processed total books: 27\n",
      "processed total books: 28\n",
      "processed total books: 29\n",
      "processed total books: 30\n",
      "processed total books: 31\n",
      "processed total books: 32\n",
      "processed total books: 33\n",
      "processed total books: 34\n",
      "processed total books: 35\n",
      "processed total books: 36\n",
      "processed total books: 37\n",
      "processed total books: 38\n",
      "Succesfully wrote 25538 paragraphs and processed 38 books -> ./Datasets/model_data/test_data.csv\n"
     ]
    }
   ],
   "source": [
    "out_file = os.path.join(model_dataset_path, \"test_data.csv\")\n",
    "write_data_to_csv(paragraph_test_data, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8bd4afcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup_model_data(model_dataset_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workbench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
