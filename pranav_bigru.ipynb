{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6fd6acb-a67a-46f7-8564-a0498fbf15f5",
   "metadata": {},
   "source": [
    "# Assignment 4, task 1\n",
    "\n",
    "In this task, we will have a final crack at the NER problem, using recurrent neural networks, or Gated Recurrent Units (GRUs) to be more exact.\n",
    "\n",
    "We want to consider both the context of the word (the surrounding words) and the contents of the word (the letters and other symbols that make up the actual word). Therefore we are using two bi-directional GRUs, one world-level GRU for the words in the sentence, and one character-level GRU for the letters and other symbols in a word. \n",
    "\n",
    "We will process one sentence at a time. Each hidden state vector in the word-level GRU represents that word in relation to the other words in the sentence, whereas the final state vector(s) in the character-level RNN represent morphological and typographical information about the word. We will concatenate these vectors to obtain a single information-rich representation of the word."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804625a1",
   "metadata": {},
   "source": [
    "## Libraries + Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a9103d5-cadf-4599-9c4b-c5ef0115b866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First run this cell\n",
    "import csv\n",
    "import os \n",
    "import urllib.request\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "import codecs\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3570d099",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e4596d",
   "metadata": {},
   "source": [
    "### Embeddings - Pretrained GLOVE Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "481e0b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_path = './Embeddings'\n",
    "# remove the embeddings data files if they already exist\n",
    "# if os.path.exists(embeddings_path):\n",
    "#     print(f\"clean up - previous pre-trained embeddings files\")\n",
    "#     embedding_files = [f for f in os.listdir(embeddings_path) if f.endswith(\".txt\")]\n",
    "#     for file in embedding_files:\n",
    "#         file_path = os.path.join(embeddings_path, file)\n",
    "#         os.remove(file_path)\n",
    "#         print(f\"successfully removed {file}\")\n",
    "#     os.rmdir(embeddings_path)\n",
    "#     print(f\"successfully removed {embeddings_path}\")\n",
    "#     print()\n",
    "\n",
    "\n",
    "def download_progress(block_num, block_size, total_size):\n",
    "    if not hasattr(download_progress, \"pbar\"):\n",
    "        download_progress.pbar = tqdm(total=total_size, unit=\"B\", unit_scale=True)\n",
    "    download_progress.pbar.update(block_size)\n",
    "\n",
    "if not os.path.exists(embeddings_path):\n",
    "    print(f\"create directory to store pre-trained glove embeddings\")\n",
    "    os.makedirs(embeddings_path)\n",
    "    print(f\"download pre-trained Glove Embeddings\")\n",
    "    urllib.request.urlretrieve(\n",
    "        \"http://nlp.stanford.edu/data/glove.6B.zip\", \"./Embeddings/glove.6B.zip\",\n",
    "        download_progress\n",
    "    )\n",
    "    print(\"unpack embeddings\")\n",
    "    with zipfile.ZipFile(\"./Embeddings/glove.6B.zip\", \"r\") as zip_ref:\n",
    "        zip_ref.extractall(\"./Embeddings/\")\n",
    "    os.remove(\"./Embeddings/glove.6B.zip\")\n",
    "    print(\"embeddings download complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0773187d",
   "metadata": {},
   "source": [
    "### Data File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c290f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = './Datasets/model_data/train_passages.csv'\n",
    "valid_data_path = './Datasets/model_data/validation_passages.csv'\n",
    "test_data_path = './Datasets/model_data/test_passages.csv'\n",
    "embeddings_path = './Embeddings/glove.6B.50d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31cb9985-b6df-40b0-8b56-777265c79de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id_to_decade: [1700, 1710, 1720, 1730, 1740, 1750, 1760, 1770, 1780, 1790, 1800, 1810, 1820, 1830, 1840, 1850, 1860, 1870, 1880, 1890]\n",
      "decade_to_id: {1700: 0, 1710: 1, 1720: 2, 1730: 3, 1740: 4, 1750: 5, 1760: 6, 1770: 7, 1780: 8, 1790: 9, 1800: 10, 1810: 11, 1820: 12, 1830: 13, 1840: 14, 1850: 15, 1860: 16, 1870: 17, 1880: 18, 1890: 19}\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to init mappings from characters to IDs and back again,\n",
    "# from words to IDs and back again, and from labels to IDs and back again\n",
    "\n",
    "UNKNOWN = '<unk>'  # Unknown char or unknown word\n",
    "CHARS = [UNKNOWN, '’', '—'] + list(string.punctuation) + list(string.ascii_letters) + list(string.digits)\n",
    "char_to_id = {c:i for i,c in enumerate(CHARS)}\n",
    "PADDING_WORD = '<pad>'\n",
    "\n",
    "# create mappings for decades \n",
    "id_to_decade = [i for i in range(1700, 1900, 10)]\n",
    "decade_to_id = {decade: i for i, decade in enumerate(id_to_decade)}\n",
    "\n",
    "print(f\"id_to_decade: {id_to_decade}\")\n",
    "print(f\"decade_to_id: {decade_to_id}\")\n",
    "\n",
    "# id_to_label = ['noname', 'name']\n",
    "\n",
    "# def label_to_id(label):\n",
    "#     return 0 if label == 'O' else 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fa4c07-a542-4250-94e7-7583dc2a4583",
   "metadata": {},
   "source": [
    "We want to have a vector representation of the syntactic and semantic properties of words, and in order to avoid having to train these from scratch, we are going to re-use pre-trained Glove vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f1ca98e-065f-496e-8778-ee5fc43cdc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_embeddings(embedding_file,\n",
    "                          padding_word=PADDING_WORD, \n",
    "                          unknown_word=UNKNOWN):\n",
    "    \"\"\"\n",
    "    Reads Glove embeddings from a file.\n",
    "\n",
    "    Returns vector dimensionality, the word_to_id mapping (as a dict),\n",
    "    and the embeddings (as a list of lists).\n",
    "    \"\"\"\n",
    "    word_to_id = {}  # Dictionary to store word-to-ID mapping\n",
    "    word_to_id[padding_word] = 0\n",
    "    word_to_id[unknown_word] = 1\n",
    "    embeddings = []\n",
    "    with open(embedding_file, encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            data = line.split()\n",
    "            word = data[0]\n",
    "            vec = [float(x) for x in data[1:]]\n",
    "            embeddings.append(vec)\n",
    "            word_to_id[word] = len(word_to_id)\n",
    "    D = len(embeddings[0])\n",
    "\n",
    "    embeddings.insert(word_to_id[padding_word], [0]*D)  # <PAD> has an embedding of just zeros\n",
    "    embeddings.insert(word_to_id[unknown_word], [-1]*D)      # <UNK> has an embedding of just minus-ones\n",
    "\n",
    "    return D, word_to_id, embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffb5db8-b6f8-42d9-82b6-fd65e05f5f34",
   "metadata": {},
   "source": [
    "We can now create our dataset. Each datapoint will consist of a sentence and its associated labels for each word in the sentence. The label is either 1 (a name) or 0 (not a name). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "767c1320-1489-4865-ada3-40e7276570db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HistoricalTextDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A class loading historical text passages from CSV for input to PyTorch DataLoader\n",
    "    CSV format: text, decade, book_title, passage_id, decade_id, book_id\n",
    "    \"\"\"\n",
    "    def __init__(self, filename, word_to_id, max_length=300):\n",
    "        self.word_to_id = word_to_id\n",
    "        self.max_length = max_length\n",
    "\n",
    "        df = pd.read_csv(filename)\n",
    "\n",
    "        self.texts = []\n",
    "        self.decade_ids = []\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            text = row[\"text\"]\n",
    "            # take the first max number of words from the passage\n",
    "            words = text.lower().split()[:max_length]\n",
    "            decade_id = row[\"decade_id\"]\n",
    "\n",
    "            self.texts.append(words)\n",
    "            self.decade_ids.append(decade_id)\n",
    "\n",
    "        print(f\"Loaded {len(self.texts)} passages from {filename}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx], self.decade_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b78440d-4a87-460f-862c-7b5b769d3eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The embedding for the word 'good' looks like this:\n",
      "[-0.35586, 0.5213, -0.6107, -0.30131, 0.94862, -0.31539, -0.59831, 0.12188, -0.031943, 0.55695, -0.10621, 0.63399, -0.4734, -0.075895, 0.38247, 0.081569, 0.82214, 0.2222, -0.0083764, -0.7662, -0.56253, 0.61759, 0.20292, -0.048598, 0.87815, -1.6549, -0.77418, 0.15435, 0.94823, -0.3952, 3.7302, 0.82855, -0.14104, 0.016395, 0.21115, -0.036085, -0.15587, 0.86583, 0.26309, -0.71015, -0.03677, 0.0018282, -0.17704, 0.27032, 0.11026, 0.14133, -0.057322, 0.27207, 0.31305, 0.92771]\n",
      "\n",
      "Loaded 200 passages from ./Datasets/model_data/test_passages.csv\n",
      "There are 200 data points in the testset\n",
      "Data point 100 passage: ['uppressions', 'and', 'reserve.', 'their', 'members', 'were', 'brethren', 'in', 'disposition,', 'similar', 'in', 'their', 'pursuits,', 'and', 'congenial', 'in', 'their', 'sentiments.', 'when', 'any'] ...\n",
      "It has the decade_id: 10 which corresponds to decade: 1800\n"
     ]
    }
   ],
   "source": [
    "# Let's check out some of these data structures\n",
    "# dim, word_to_id, embeddings = load_glove_embeddings('/datasets/dd2417/glove.6B.50d.txt')\n",
    "dim, word_to_id, embeddings = load_glove_embeddings(f\"{embeddings_path}\")\n",
    "print(\"The embedding for the word 'good' looks like this:\")\n",
    "print(embeddings[word_to_id['good']])\n",
    "print()\n",
    "\n",
    "# Read the data we are going to use for testing the model\n",
    "test_set = HistoricalTextDataset(f'{test_data_path}', word_to_id)\n",
    "print(\"There are\", len(test_set), \"data points in the testset\")\n",
    "dp = 100\n",
    "passage, decade_id = test_set[dp]\n",
    "print(\"Data point\", dp, \"passage:\", passage[:20], \"...\") \n",
    "print(\"It has the decade_id:\", decade_id, \"which corresponds to decade:\", id_to_decade[decade_id],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c30114fe-2993-491c-9b5c-9a1870ff1892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell. The function below will take care of the case of\n",
    "# sequences of unequal lengths.\n",
    "def pad_text_sequences(batch, padding_word=PADDING_WORD):\n",
    "    batch_texts, batch_decade_ids = zip(*batch)\n",
    "    max_len = max(map(len, batch_texts))\n",
    "    padded_texts = [\n",
    "        [text[i] if i < len(text) else padding_word for i in range(max_len)]\n",
    "        for text in batch_texts\n",
    "    ]\n",
    "    return padded_texts, list(batch_decade_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd4b1b2e-e8db-4bec-b4ad-3bb1681efeed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['hello', 'world', 'text', '<pad>'],\n",
       "  ['short', 'passage', '<pad>', '<pad>'],\n",
       "  ['longer', 'historical', 'passage', 'here']],\n",
       " [5, 12, 8])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is how it works\n",
    "x = [\n",
    "    ([\"hello\", \"world\", \"text\"], 5),\n",
    "    ([\"short\", \"passage\"], 12),\n",
    "    ([\"longer\", \"historical\", \"passage\", \"here\"], 8),\n",
    "]\n",
    "pad_text_sequences(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cbc550-82c8-4a5a-8e35-faf3c1682232",
   "metadata": {},
   "source": [
    "Here is the actual classifier, as a class extending the Pytorch 'nn.Module' class. Your task is to write the forward function (look for \"YOUR CODE HERE\" below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6c9668-fbb3-4cfc-a173-7f8b590c2169",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HistoricalTextClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, word_embeddings,  # Pre-trained word embeddings\n",
    "                    char_to_id,             # Mapping from chars to ids\n",
    "                    word_to_id,             # Mapping from words to ids\n",
    "                    char_emb_size=12,\n",
    "                    char_hidden_size=20,    # Hidden size of the character-level biRNN\n",
    "                    word_hidden_size=48,   # Hidden size of the word-level biRNN\n",
    "                    padding_word=PADDING_WORD,\n",
    "                    unknown_word=UNKNOWN,\n",
    "                    char_bidirectional=True,\n",
    "                    word_bidirectional=True,\n",
    "                    device=None             \n",
    "                ):\n",
    "\n",
    "        super(HistoricalTextClassifier, self).__init__()\n",
    "        if device is None:\n",
    "            if torch.cuda.is_available():\n",
    "                self.device = \"cuda\"\n",
    "                print(\"Using CUDA GPU\")\n",
    "            elif torch.backends.mps.is_available():\n",
    "                self.device = \"mps\"\n",
    "                print(\"Using Apple M3 Pro GPU (MPS)\")\n",
    "            else:\n",
    "                self.device = \"cpu\"\n",
    "                print(\"Using CPU\")\n",
    "        else:\n",
    "            self.device = device\n",
    "            print(f\"Using specified device: {device}\")\n",
    "\n",
    "        self.padding_word = padding_word\n",
    "        self.unknown_word = unknown_word\n",
    "        self.char_to_id = char_to_id\n",
    "        self.word_to_id = word_to_id\n",
    "        self.char_emb_size = char_emb_size\n",
    "        self.char_hidden_size = char_hidden_size\n",
    "        self.word_hidden_size = word_hidden_size\n",
    "        self.char_bidirectional = char_bidirectional\n",
    "        self.word_bidirectional = word_bidirectional\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "        # Create an embedding tensor for the words and import the Glove\n",
    "        # embeddings. The embeddings are frozen (i.e., they will not be\n",
    "        # updated during training).\n",
    "        vocabulary_size = len(word_embeddings)\n",
    "        self.word_emb_size = len(word_embeddings[0])\n",
    "\n",
    "        self.word_emb = nn.Embedding(vocabulary_size, self.word_emb_size)\n",
    "        self.word_emb.weight = nn.Parameter(\n",
    "            torch.tensor(word_embeddings, dtype=torch.float), requires_grad=False\n",
    "        )\n",
    "\n",
    "        # Create an embedding tensor for character embeddings. These embeddings\n",
    "        # are learnt from scratch (i.e., they are not frozen).\n",
    "        if self.char_emb_size > 0:\n",
    "            self.char_emb = nn.Embedding(len(char_to_id), char_emb_size)\n",
    "            self.char_birnn = nn.GRU(\n",
    "                self.char_emb_size,\n",
    "                self.char_hidden_size,\n",
    "                bidirectional=char_bidirectional,\n",
    "                batch_first=True,\n",
    "            )\n",
    "        else:\n",
    "            self.char_hidden_size = 0\n",
    "\n",
    "        multiplier = 2 if self.char_bidirectional else 1\n",
    "        self.word_birnn = nn.GRU(\n",
    "            self.word_emb_size + multiplier * self.char_hidden_size, # input size\n",
    "            self.word_hidden_size,\n",
    "            bidirectional=word_bidirectional,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        # Multi-class classification - predict one of the 20 decades (1700-1890)\n",
    "        multiplier = 2 if self.word_bidirectional else 1\n",
    "        self.final_pred = nn.Sequential(\n",
    "            nn.Linear(multiplier * self.word_hidden_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 20),\n",
    "        )\n",
    "\n",
    "        # self.final_pred = nn.Linear(multiplier * self.word_hidden_size, 20)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Performs a forward pass of Historical Text Dating Classifier \n",
    "        Takes as input a 2D list `x` of dimensionality (B, T),\n",
    "        where B is the batch size;\n",
    "        T is the max passage length in the batch (shorter passages\n",
    "        are already padded with the special token <PAD>)\n",
    "\n",
    "        Returns logits for decade classification (20 classes).\n",
    "\n",
    "        :param      x:    A batch of text passages\n",
    "        :type       x:    list of list of strings\n",
    "        \"\"\"\n",
    "\n",
    "        # First find all word IDs of all words in all sentences in the batch\n",
    "        # and the character IDs of all characters in all words in all sentences\n",
    "        word_ids = []  # REPLACE WITH YOUR CODE\n",
    "        char_ids = []  # REPLACE WITH YOUR CODE\n",
    "\n",
    "        if self.char_emb_size > 0:\n",
    "            max_word_length = 0\n",
    "            for passage in x:\n",
    "                for word in passage:\n",
    "                    max_word_length = max(max_word_length, len(word))\n",
    "            max_word_length = min(max_word_length, 20)\n",
    "        else:\n",
    "            max_word_length = 0  # Not needed when char_emb_size = 0\n",
    "\n",
    "        # convert words to ids and characters to ids\n",
    "        for passage in x:\n",
    "            passage_word_ids = []\n",
    "            passage_char_ids = []\n",
    "            for word in passage:\n",
    "                # word to id\n",
    "                if word in self.word_to_id:\n",
    "                    passage_word_ids.append(self.word_to_id[word])\n",
    "                else:\n",
    "                    passage_word_ids.append(self.word_to_id[self.unknown_word])\n",
    "\n",
    "                if self.char_emb_size > 0:\n",
    "                    word_char_ids = []\n",
    "                    for char in word:\n",
    "                        # word chars to id\n",
    "                        if char in self.char_to_id:\n",
    "                            word_char_ids.append(self.char_to_id[char])\n",
    "                        else:\n",
    "                            word_char_ids.append(self.char_to_id[UNKNOWN])\n",
    "\n",
    "                    word_char_ids = word_char_ids[:max_word_length]\n",
    "\n",
    "                    # pad words of unequal length to max word length\n",
    "                    while len(word_char_ids) < max_word_length:\n",
    "                        word_char_ids.append(self.char_to_id[UNKNOWN])\n",
    "\n",
    "                    passage_char_ids.append(word_char_ids)\n",
    "\n",
    "            word_ids.append(passage_word_ids)\n",
    "            if self.char_emb_size > 0:\n",
    "                char_ids.append(passage_char_ids)\n",
    "\n",
    "        # The 'to(self.device)' below is necessary for making sure that\n",
    "        # the model and the data are on the same device (CPU or CUDA).\n",
    "        word_tensor = torch.tensor(word_ids, device=next(self.parameters()).device)\n",
    "\n",
    "        if self.char_emb_size > 0:\n",
    "            char_tensor = torch.tensor(char_ids, device=next(self.parameters()).device)\n",
    "\n",
    "        # Get word embeddings\n",
    "        word_embeddings = self.word_emb(word_tensor)\n",
    "\n",
    "        if self.char_emb_size > 0:\n",
    "            batch_size, max_passage_length, actual_max_word_length = char_tensor.shape\n",
    "\n",
    "            # reshape for character processing - process individual words\n",
    "            char_tensor_reshape = char_tensor.view(\n",
    "                batch_size * max_passage_length, actual_max_word_length\n",
    "            )\n",
    "            char_embeddings = self.char_emb(char_tensor_reshape)\n",
    "\n",
    "            # run bigru on characters\n",
    "            char_output, char_hidden = self.char_birnn(char_embeddings)\n",
    "\n",
    "            # 0 - forward, 1 - backward\n",
    "            # combine forward and backward features\n",
    "            if self.char_bidirectional:\n",
    "                char_features = torch.cat([char_hidden[0], char_hidden[1]], dim=1)\n",
    "            else:\n",
    "                char_features = char_hidden.squeeze(0)\n",
    "\n",
    "            # reshape from words to passage\n",
    "            char_features = char_features.view(batch_size, max_passage_length, -1)\n",
    "\n",
    "            # word + character features\n",
    "            combined_features = torch.cat([word_embeddings, char_features], dim=2)\n",
    "\n",
    "        else:\n",
    "            combined_features = word_embeddings\n",
    "\n",
    "        # run bigru on words\n",
    "        word_output, _ = self.word_birnn(combined_features)\n",
    "\n",
    "        # doc_representation = torch.mean(word_output, dim=1)\n",
    "        attention_weights = torch.softmax(torch.sum(word_output, dim=2, keepdim=True), dim=1)\n",
    "        doc_representation = torch.sum(attention_weights * word_output, dim=1)\n",
    "\n",
    "        doc_representation = self.dropout(doc_representation)\n",
    "\n",
    "        # predict the year\n",
    "        logits = self.final_pred(doc_representation)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3108f77-1bc5-4ac1-96fa-380d6c02a8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 800 passages from ./Datasets/model_data/train_passages.csv\n",
      "Loaded 300 passages from ./Datasets/model_data/validation_passages.csv\n",
      "Using Apple M3 Pro GPU (MPS)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [Train]: 100%|██████████| 100/100 [00:37<00:00,  2.69it/s]\n",
      "Epoch 1 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80:\n",
      "Train Loss: 2.9986, Train Acc: 0.0550\n",
      "Val Loss: 2.9987, Val Acc: 0.0500\n",
      "  New best model saved! Best: 0.0500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 [Train]: 100%|██████████| 100/100 [00:35<00:00,  2.80it/s]\n",
      "Epoch 2 [Val]: 100%|██████████| 38/38 [00:05<00:00,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/80:\n",
      "Train Loss: 2.9977, Train Acc: 0.0488\n",
      "Val Loss: 2.9973, Val Acc: 0.0500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 [Train]: 100%|██████████| 100/100 [00:37<00:00,  2.65it/s]\n",
      "Epoch 3 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/80:\n",
      "Train Loss: 2.9949, Train Acc: 0.0612\n",
      "Val Loss: 2.9972, Val Acc: 0.0333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 [Train]: 100%|██████████| 100/100 [00:35<00:00,  2.85it/s]\n",
      "Epoch 4 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/80:\n",
      "Train Loss: 2.9930, Train Acc: 0.0425\n",
      "Val Loss: 2.9968, Val Acc: 0.0600\n",
      "  New best model saved! Best: 0.0600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 [Train]: 100%|██████████| 100/100 [00:36<00:00,  2.78it/s]\n",
      "Epoch 5 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/80:\n",
      "Train Loss: 2.9909, Train Acc: 0.0650\n",
      "Val Loss: 2.9960, Val Acc: 0.0500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 [Train]: 100%|██████████| 100/100 [00:36<00:00,  2.78it/s]\n",
      "Epoch 6 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/80:\n",
      "Train Loss: 2.9845, Train Acc: 0.0625\n",
      "Val Loss: 2.9956, Val Acc: 0.0567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 [Train]: 100%|██████████| 100/100 [00:35<00:00,  2.85it/s]\n",
      "Epoch 7 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/80:\n",
      "Train Loss: 2.9858, Train Acc: 0.0775\n",
      "Val Loss: 2.9951, Val Acc: 0.0500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 [Train]: 100%|██████████| 100/100 [00:34<00:00,  2.90it/s]\n",
      "Epoch 8 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/80:\n",
      "Train Loss: 2.9843, Train Acc: 0.0663\n",
      "Val Loss: 2.9949, Val Acc: 0.0467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 [Train]: 100%|██████████| 100/100 [00:34<00:00,  2.90it/s]\n",
      "Epoch 9 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/80:\n",
      "Train Loss: 2.9824, Train Acc: 0.0737\n",
      "Val Loss: 2.9945, Val Acc: 0.0433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 [Train]: 100%|██████████| 100/100 [00:34<00:00,  2.87it/s]\n",
      "Epoch 10 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/80:\n",
      "Train Loss: 2.9812, Train Acc: 0.0600\n",
      "Val Loss: 2.9939, Val Acc: 0.0367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 [Train]: 100%|██████████| 100/100 [00:35<00:00,  2.78it/s]\n",
      "Epoch 11 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/80:\n",
      "Train Loss: 2.9795, Train Acc: 0.0663\n",
      "Val Loss: 2.9936, Val Acc: 0.0467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 [Train]: 100%|██████████| 100/100 [00:35<00:00,  2.80it/s]\n",
      "Epoch 12 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/80:\n",
      "Train Loss: 2.9781, Train Acc: 0.0725\n",
      "Val Loss: 2.9928, Val Acc: 0.0400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 [Train]: 100%|██████████| 100/100 [00:35<00:00,  2.81it/s]\n",
      "Epoch 13 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/80:\n",
      "Train Loss: 2.9739, Train Acc: 0.0825\n",
      "Val Loss: 2.9930, Val Acc: 0.0367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 [Train]: 100%|██████████| 100/100 [00:34<00:00,  2.88it/s]\n",
      "Epoch 14 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/80:\n",
      "Train Loss: 2.9705, Train Acc: 0.0725\n",
      "Val Loss: 2.9914, Val Acc: 0.0300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 [Train]: 100%|██████████| 100/100 [00:34<00:00,  2.89it/s]\n",
      "Epoch 15 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/80:\n",
      "Train Loss: 2.9662, Train Acc: 0.0887\n",
      "Val Loss: 2.9905, Val Acc: 0.0433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 [Train]: 100%|██████████| 100/100 [00:34<00:00,  2.87it/s]\n",
      "Epoch 16 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/80:\n",
      "Train Loss: 2.9610, Train Acc: 0.0862\n",
      "Val Loss: 2.9894, Val Acc: 0.0333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17 [Train]: 100%|██████████| 100/100 [00:34<00:00,  2.88it/s]\n",
      "Epoch 17 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/80:\n",
      "Train Loss: 2.9587, Train Acc: 0.0813\n",
      "Val Loss: 2.9889, Val Acc: 0.0567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18 [Train]: 100%|██████████| 100/100 [00:34<00:00,  2.87it/s]\n",
      "Epoch 18 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/80:\n",
      "Train Loss: 2.9499, Train Acc: 0.0963\n",
      "Val Loss: 2.9886, Val Acc: 0.0533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19 [Train]: 100%|██████████| 100/100 [00:34<00:00,  2.86it/s]\n",
      "Epoch 19 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/80:\n",
      "Train Loss: 2.9396, Train Acc: 0.0862\n",
      "Val Loss: 2.9854, Val Acc: 0.0533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20 [Train]: 100%|██████████| 100/100 [00:34<00:00,  2.86it/s]\n",
      "Epoch 20 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/80:\n",
      "Train Loss: 2.9303, Train Acc: 0.0950\n",
      "Val Loss: 2.9861, Val Acc: 0.0433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21 [Train]: 100%|██████████| 100/100 [00:35<00:00,  2.85it/s]\n",
      "Epoch 21 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/80:\n",
      "Train Loss: 2.9258, Train Acc: 0.0988\n",
      "Val Loss: 2.9869, Val Acc: 0.0467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22 [Train]: 100%|██████████| 100/100 [00:34<00:00,  2.86it/s]\n",
      "Epoch 22 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/80:\n",
      "Train Loss: 2.9157, Train Acc: 0.0925\n",
      "Val Loss: 2.9849, Val Acc: 0.0533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23 [Train]: 100%|██████████| 100/100 [00:34<00:00,  2.87it/s]\n",
      "Epoch 23 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/80:\n",
      "Train Loss: 2.9095, Train Acc: 0.0988\n",
      "Val Loss: 2.9891, Val Acc: 0.0433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24 [Train]: 100%|██████████| 100/100 [00:34<00:00,  2.87it/s]\n",
      "Epoch 24 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/80:\n",
      "Train Loss: 2.9085, Train Acc: 0.1062\n",
      "Val Loss: 2.9862, Val Acc: 0.0500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25 [Train]: 100%|██████████| 100/100 [00:34<00:00,  2.86it/s]\n",
      "Epoch 25 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/80:\n",
      "Train Loss: 2.9030, Train Acc: 0.0975\n",
      "Val Loss: 2.9912, Val Acc: 0.0467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26 [Train]: 100%|██████████| 100/100 [00:35<00:00,  2.84it/s]\n",
      "Epoch 26 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/80:\n",
      "Train Loss: 2.8991, Train Acc: 0.1013\n",
      "Val Loss: 2.9945, Val Acc: 0.0500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27 [Train]: 100%|██████████| 100/100 [00:34<00:00,  2.89it/s]\n",
      "Epoch 27 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/80:\n",
      "Train Loss: 2.8952, Train Acc: 0.0950\n",
      "Val Loss: 2.9888, Val Acc: 0.0533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28 [Train]: 100%|██████████| 100/100 [00:35<00:00,  2.81it/s]\n",
      "Epoch 28 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/80:\n",
      "Train Loss: 2.8851, Train Acc: 0.0975\n",
      "Val Loss: 2.9920, Val Acc: 0.0400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29 [Train]: 100%|██████████| 100/100 [00:34<00:00,  2.87it/s]\n",
      "Epoch 29 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/80:\n",
      "Train Loss: 2.8921, Train Acc: 0.0887\n",
      "Val Loss: 2.9892, Val Acc: 0.0500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30 [Train]: 100%|██████████| 100/100 [00:35<00:00,  2.85it/s]\n",
      "Epoch 30 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/80:\n",
      "Train Loss: 2.8924, Train Acc: 0.0862\n",
      "Val Loss: 2.9908, Val Acc: 0.0567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31 [Train]: 100%|██████████| 100/100 [00:34<00:00,  2.86it/s]\n",
      "Epoch 31 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/80:\n",
      "Train Loss: 2.8905, Train Acc: 0.1075\n",
      "Val Loss: 2.9932, Val Acc: 0.0400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32 [Train]: 100%|██████████| 100/100 [00:34<00:00,  2.87it/s]\n",
      "Epoch 32 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/80:\n",
      "Train Loss: 2.8780, Train Acc: 0.0963\n",
      "Val Loss: 3.0007, Val Acc: 0.0333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33 [Train]: 100%|██████████| 100/100 [00:34<00:00,  2.88it/s]\n",
      "Epoch 33 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/80:\n",
      "Train Loss: 2.8889, Train Acc: 0.1000\n",
      "Val Loss: 2.9900, Val Acc: 0.0500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34 [Train]: 100%|██████████| 100/100 [00:35<00:00,  2.83it/s]\n",
      "Epoch 34 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/80:\n",
      "Train Loss: 2.8804, Train Acc: 0.1000\n",
      "Val Loss: 2.9912, Val Acc: 0.0533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35 [Train]: 100%|██████████| 100/100 [00:35<00:00,  2.83it/s]\n",
      "Epoch 35 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/80:\n",
      "Train Loss: 2.8820, Train Acc: 0.0975\n",
      "Val Loss: 3.0179, Val Acc: 0.0467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36 [Train]: 100%|██████████| 100/100 [00:36<00:00,  2.76it/s]\n",
      "Epoch 36 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/80:\n",
      "Train Loss: 2.8776, Train Acc: 0.1050\n",
      "Val Loss: 2.9903, Val Acc: 0.0400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37 [Train]: 100%|██████████| 100/100 [00:35<00:00,  2.82it/s]\n",
      "Epoch 37 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/80:\n",
      "Train Loss: 2.8759, Train Acc: 0.1037\n",
      "Val Loss: 2.9955, Val Acc: 0.0400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38 [Train]: 100%|██████████| 100/100 [00:36<00:00,  2.72it/s]\n",
      "Epoch 38 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/80:\n",
      "Train Loss: 2.8778, Train Acc: 0.0925\n",
      "Val Loss: 2.9906, Val Acc: 0.0500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39 [Train]: 100%|██████████| 100/100 [00:38<00:00,  2.58it/s]\n",
      "Epoch 39 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/80:\n",
      "Train Loss: 2.8679, Train Acc: 0.0925\n",
      "Val Loss: 2.9914, Val Acc: 0.0533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40 [Train]: 100%|██████████| 100/100 [00:35<00:00,  2.84it/s]\n",
      "Epoch 40 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/80:\n",
      "Train Loss: 2.8759, Train Acc: 0.0950\n",
      "Val Loss: 3.0017, Val Acc: 0.0367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41 [Train]: 100%|██████████| 100/100 [00:35<00:00,  2.84it/s]\n",
      "Epoch 41 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/80:\n",
      "Train Loss: 2.8699, Train Acc: 0.1025\n",
      "Val Loss: 2.9967, Val Acc: 0.0367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42 [Train]: 100%|██████████| 100/100 [00:35<00:00,  2.84it/s]\n",
      "Epoch 42 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/80:\n",
      "Train Loss: 2.8746, Train Acc: 0.1037\n",
      "Val Loss: 2.9899, Val Acc: 0.0433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43 [Train]: 100%|██████████| 100/100 [00:35<00:00,  2.82it/s]\n",
      "Epoch 43 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/80:\n",
      "Train Loss: 2.8713, Train Acc: 0.1050\n",
      "Val Loss: 2.9957, Val Acc: 0.0433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44 [Train]: 100%|██████████| 100/100 [00:34<00:00,  2.86it/s]\n",
      "Epoch 44 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/80:\n",
      "Train Loss: 2.8703, Train Acc: 0.0925\n",
      "Val Loss: 3.0009, Val Acc: 0.0367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45 [Train]: 100%|██████████| 100/100 [00:35<00:00,  2.86it/s]\n",
      "Epoch 45 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/80:\n",
      "Train Loss: 2.8668, Train Acc: 0.1075\n",
      "Val Loss: 2.9893, Val Acc: 0.0400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46 [Train]: 100%|██████████| 100/100 [00:35<00:00,  2.81it/s]\n",
      "Epoch 46 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/80:\n",
      "Train Loss: 2.8637, Train Acc: 0.0963\n",
      "Val Loss: 2.9890, Val Acc: 0.0367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47 [Train]: 100%|██████████| 100/100 [00:34<00:00,  2.86it/s]\n",
      "Epoch 47 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/80:\n",
      "Train Loss: 2.8610, Train Acc: 0.1050\n",
      "Val Loss: 2.9956, Val Acc: 0.0400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48 [Train]: 100%|██████████| 100/100 [00:35<00:00,  2.78it/s]\n",
      "Epoch 48 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/80:\n",
      "Train Loss: 2.8706, Train Acc: 0.1000\n",
      "Val Loss: 2.9882, Val Acc: 0.0533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49 [Train]: 100%|██████████| 100/100 [00:34<00:00,  2.89it/s]\n",
      "Epoch 49 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/80:\n",
      "Train Loss: 2.8588, Train Acc: 0.1113\n",
      "Val Loss: 2.9916, Val Acc: 0.0400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50 [Train]: 100%|██████████| 100/100 [00:34<00:00,  2.91it/s]\n",
      "Epoch 50 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/80:\n",
      "Train Loss: 2.8617, Train Acc: 0.1075\n",
      "Val Loss: 2.9873, Val Acc: 0.0400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51 [Train]: 100%|██████████| 100/100 [00:35<00:00,  2.84it/s]\n",
      "Epoch 51 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/80:\n",
      "Train Loss: 2.8530, Train Acc: 0.1013\n",
      "Val Loss: 2.9881, Val Acc: 0.0400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52 [Train]: 100%|██████████| 100/100 [00:34<00:00,  2.90it/s]\n",
      "Epoch 52 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/80:\n",
      "Train Loss: 2.8542, Train Acc: 0.1138\n",
      "Val Loss: 2.9885, Val Acc: 0.0400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53 [Train]: 100%|██████████| 100/100 [00:34<00:00,  2.90it/s]\n",
      "Epoch 53 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80:\n",
      "Train Loss: 2.8515, Train Acc: 0.1000\n",
      "Val Loss: 2.9894, Val Acc: 0.0333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54 [Train]: 100%|██████████| 100/100 [00:34<00:00,  2.92it/s]\n",
      "Epoch 54 [Val]: 100%|██████████| 38/38 [00:04<00:00,  7.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/80:\n",
      "Train Loss: 2.8531, Train Acc: 0.1062\n",
      "Val Loss: 2.9887, Val Acc: 0.0433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55 [Train]: 100%|██████████| 100/100 [00:35<00:00,  2.81it/s]\n",
      "Epoch 55 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/80:\n",
      "Train Loss: 2.8557, Train Acc: 0.1075\n",
      "Val Loss: 2.9971, Val Acc: 0.0500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56 [Train]: 100%|██████████| 100/100 [00:34<00:00,  2.87it/s]\n",
      "Epoch 56 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/80:\n",
      "Train Loss: 2.8532, Train Acc: 0.1125\n",
      "Val Loss: 2.9898, Val Acc: 0.0400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57 [Train]: 100%|██████████| 100/100 [00:33<00:00,  2.97it/s]\n",
      "Epoch 57 [Val]: 100%|██████████| 38/38 [00:04<00:00,  9.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/80:\n",
      "Train Loss: 2.8525, Train Acc: 0.1125\n",
      "Val Loss: 2.9890, Val Acc: 0.0400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58 [Train]: 100%|██████████| 100/100 [00:34<00:00,  2.92it/s]\n",
      "Epoch 58 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/80:\n",
      "Train Loss: 2.8560, Train Acc: 0.1062\n",
      "Val Loss: 2.9923, Val Acc: 0.0433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59 [Train]: 100%|██████████| 100/100 [00:35<00:00,  2.82it/s]\n",
      "Epoch 59 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/80:\n",
      "Train Loss: 2.8570, Train Acc: 0.1125\n",
      "Val Loss: 2.9894, Val Acc: 0.0400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60 [Train]: 100%|██████████| 100/100 [00:35<00:00,  2.84it/s]\n",
      "Epoch 60 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/80:\n",
      "Train Loss: 2.8457, Train Acc: 0.1125\n",
      "Val Loss: 2.9930, Val Acc: 0.0400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61 [Train]: 100%|██████████| 100/100 [00:34<00:00,  2.93it/s]\n",
      "Epoch 61 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/80:\n",
      "Train Loss: 2.8415, Train Acc: 0.1013\n",
      "Val Loss: 2.9963, Val Acc: 0.0600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62 [Train]: 100%|██████████| 100/100 [00:34<00:00,  2.89it/s]\n",
      "Epoch 62 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/80:\n",
      "Train Loss: 2.8451, Train Acc: 0.0975\n",
      "Val Loss: 2.9997, Val Acc: 0.0633\n",
      "  New best model saved! Best: 0.0633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63 [Train]: 100%|██████████| 100/100 [00:34<00:00,  2.90it/s]\n",
      "Epoch 63 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/80:\n",
      "Train Loss: 2.8564, Train Acc: 0.1125\n",
      "Val Loss: 2.9907, Val Acc: 0.0333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64 [Train]: 100%|██████████| 100/100 [00:34<00:00,  2.91it/s]\n",
      "Epoch 64 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/80:\n",
      "Train Loss: 2.8410, Train Acc: 0.1225\n",
      "Val Loss: 2.9932, Val Acc: 0.0400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65 [Train]: 100%|██████████| 100/100 [00:34<00:00,  2.89it/s]\n",
      "Epoch 65 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/80:\n",
      "Train Loss: 2.8430, Train Acc: 0.1075\n",
      "Val Loss: 3.0069, Val Acc: 0.0567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66 [Train]: 100%|██████████| 100/100 [00:33<00:00,  2.95it/s]\n",
      "Epoch 66 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/80:\n",
      "Train Loss: 2.8518, Train Acc: 0.1212\n",
      "Val Loss: 2.9881, Val Acc: 0.0300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67 [Train]: 100%|██████████| 100/100 [00:34<00:00,  2.91it/s]\n",
      "Epoch 67 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/80:\n",
      "Train Loss: 2.8435, Train Acc: 0.1075\n",
      "Val Loss: 3.0008, Val Acc: 0.0600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68 [Train]: 100%|██████████| 100/100 [00:34<00:00,  2.90it/s]\n",
      "Epoch 68 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/80:\n",
      "Train Loss: 2.8445, Train Acc: 0.1050\n",
      "Val Loss: 2.9892, Val Acc: 0.0200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69 [Train]: 100%|██████████| 100/100 [00:34<00:00,  2.87it/s]\n",
      "Epoch 69 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/80:\n",
      "Train Loss: 2.8439, Train Acc: 0.1150\n",
      "Val Loss: 2.9895, Val Acc: 0.0400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70 [Train]: 100%|██████████| 100/100 [00:34<00:00,  2.86it/s]\n",
      "Epoch 70 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/80:\n",
      "Train Loss: 2.8361, Train Acc: 0.1075\n",
      "Val Loss: 2.9919, Val Acc: 0.0400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71 [Train]: 100%|██████████| 100/100 [00:34<00:00,  2.92it/s]\n",
      "Epoch 71 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/80:\n",
      "Train Loss: 2.8386, Train Acc: 0.1212\n",
      "Val Loss: 2.9902, Val Acc: 0.0233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72 [Train]: 100%|██████████| 100/100 [00:35<00:00,  2.86it/s]\n",
      "Epoch 72 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/80:\n",
      "Train Loss: 2.8378, Train Acc: 0.1200\n",
      "Val Loss: 2.9928, Val Acc: 0.0467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73 [Train]: 100%|██████████| 100/100 [00:34<00:00,  2.90it/s]\n",
      "Epoch 73 [Val]: 100%|██████████| 38/38 [00:05<00:00,  7.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/80:\n",
      "Train Loss: 2.8383, Train Acc: 0.1138\n",
      "Val Loss: 2.9896, Val Acc: 0.0300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74 [Train]: 100%|██████████| 100/100 [00:34<00:00,  2.88it/s]\n",
      "Epoch 74 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/80:\n",
      "Train Loss: 2.8322, Train Acc: 0.1138\n",
      "Val Loss: 2.9911, Val Acc: 0.0300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75 [Train]: 100%|██████████| 100/100 [00:34<00:00,  2.87it/s]\n",
      "Epoch 75 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/80:\n",
      "Train Loss: 2.8347, Train Acc: 0.1237\n",
      "Val Loss: 2.9924, Val Acc: 0.0200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76 [Train]: 100%|██████████| 100/100 [00:35<00:00,  2.83it/s]\n",
      "Epoch 76 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/80:\n",
      "Train Loss: 2.8310, Train Acc: 0.1138\n",
      "Val Loss: 2.9929, Val Acc: 0.0367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77 [Train]: 100%|██████████| 100/100 [00:34<00:00,  2.93it/s]\n",
      "Epoch 77 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/80:\n",
      "Train Loss: 2.8407, Train Acc: 0.1113\n",
      "Val Loss: 2.9913, Val Acc: 0.0233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78 [Train]: 100%|██████████| 100/100 [00:35<00:00,  2.79it/s]\n",
      "Epoch 78 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/80:\n",
      "Train Loss: 2.8376, Train Acc: 0.1125\n",
      "Val Loss: 2.9924, Val Acc: 0.0567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79 [Train]: 100%|██████████| 100/100 [00:35<00:00,  2.84it/s]\n",
      "Epoch 79 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/80:\n",
      "Train Loss: 2.8357, Train Acc: 0.1138\n",
      "Val Loss: 3.0037, Val Acc: 0.0433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80 [Train]: 100%|██████████| 100/100 [00:34<00:00,  2.90it/s]\n",
      "Epoch 80 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/80:\n",
      "Train Loss: 2.8313, Train Acc: 0.1087\n",
      "Val Loss: 2.9975, Val Acc: 0.0467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ================== Hyper-parameters ==================== #\n",
    "\n",
    "learning_rate = 0.0001\n",
    "epochs = 80\n",
    "# ======================= Training ======================= #\n",
    "dim, word_to_id, embeddings = load_glove_embeddings(f'{embeddings_path}')\n",
    "training_set = HistoricalTextDataset(f'{train_data_path}', word_to_id, max_length=150)\n",
    "validation_set = HistoricalTextDataset(f'{valid_data_path}', word_to_id, max_length=150)\n",
    "\n",
    "training_loader = DataLoader(training_set, batch_size=8, collate_fn=pad_text_sequences, shuffle=True)\n",
    "validation_loader = DataLoader(validation_set, batch_size=8, collate_fn=pad_text_sequences, shuffle=False)\n",
    "\n",
    "model = HistoricalTextClassifier(embeddings, char_to_id, word_to_id, device=None)\n",
    "model = model.to(model.device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.02)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "best_val_acc = 0\n",
    "for epoch in range(epochs):\n",
    "    # training\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "\n",
    "    for x, y in tqdm(training_loader, desc=\"Epoch {} [Train]\".format(epoch + 1)):\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x)\n",
    "        labels_tensor = torch.tensor(y).to(model.device)\n",
    "        loss = criterion(logits, labels_tensor)\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(model.parameters(), 5)\n",
    "        optimizer.step()\n",
    "\n",
    "        # training metrics\n",
    "        train_loss += loss.item()\n",
    "        predicted = torch.argmax(logits, dim=1)\n",
    "        train_correct += (predicted == labels_tensor).sum().item()\n",
    "        train_total += len(y)\n",
    "\n",
    "    # validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(validation_loader, desc=\"Epoch {} [Val]\".format(epoch + 1)):\n",
    "            logits = model(x)\n",
    "            labels_tensor = torch.tensor(y).to(model.device)\n",
    "            loss = criterion(logits, labels_tensor)\n",
    "\n",
    "            # validation metrics\n",
    "            val_loss += loss.item()\n",
    "            predicted = torch.argmax(logits, dim=1)\n",
    "            val_correct += (predicted == labels_tensor).sum().item()\n",
    "            val_total += len(y)\n",
    "\n",
    "    # all metrics\n",
    "    train_acc = train_correct / train_total\n",
    "    val_acc = val_correct / val_total\n",
    "    avg_train_loss = train_loss / len(training_loader)\n",
    "    avg_val_loss = val_loss / len(validation_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}:\")\n",
    "    print(f\"Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        print(f\"  New best model saved! Best: {best_val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1b98aa-695d-4f95-96b9-a4a0d5046cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Loaded 200 passages from ./Datasets/model_data/test_passages.csv\n",
      "Test Accuracy: 0.0650\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1 1 3 1 1 0 0 1 0 0 0 0 0 0 0 0 0 2 0 0]\n",
      " [0 0 0 1 1 0 0 1 1 0 1 0 0 0 2 2 1 0 0 0]\n",
      " [0 1 1 0 1 1 0 1 0 0 1 4 0 0 0 0 0 0 0 0]\n",
      " [3 5 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0]\n",
      " [3 1 1 0 1 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0]\n",
      " [2 1 0 0 0 1 0 1 1 0 1 0 0 0 1 1 0 1 0 0]\n",
      " [2 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 3 0 1 1]\n",
      " [2 1 0 0 1 0 1 1 0 0 0 0 0 0 0 3 1 0 0 0]\n",
      " [2 0 1 0 0 0 0 2 1 0 1 1 0 0 0 0 1 0 1 0]\n",
      " [0 0 0 0 0 1 1 0 1 0 1 0 0 0 2 1 0 1 2 0]\n",
      " [0 0 4 0 0 0 0 1 0 1 0 1 0 0 0 0 1 1 0 1]\n",
      " [1 0 1 1 0 1 0 0 2 0 1 0 0 0 1 0 1 0 0 1]\n",
      " [0 1 0 2 1 3 0 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      " [0 1 2 0 0 0 0 0 1 1 0 0 0 0 0 1 3 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 3 0 2 1]\n",
      " [2 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 2 1]\n",
      " [1 2 0 0 0 1 0 0 3 0 1 0 0 0 0 0 1 0 1 0]\n",
      " [0 1 2 0 1 0 0 0 1 2 2 0 0 0 0 0 0 0 1 0]\n",
      " [2 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 2 0 5 0]\n",
      " [1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 4 2 1 0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1700       0.05      0.10      0.06        10\n",
      "        1710       0.00      0.00      0.00        10\n",
      "        1720       0.06      0.10      0.07        10\n",
      "        1730       0.00      0.00      0.00        10\n",
      "        1740       0.14      0.10      0.12        10\n",
      "        1750       0.11      0.10      0.11        10\n",
      "        1760       0.00      0.00      0.00        10\n",
      "        1770       0.11      0.10      0.11        10\n",
      "        1780       0.08      0.10      0.09        10\n",
      "        1790       0.00      0.00      0.00        10\n",
      "        1800       0.00      0.00      0.00        10\n",
      "        1810       0.00      0.00      0.00        10\n",
      "        1820       0.00      0.00      0.00        10\n",
      "        1830       0.00      0.00      0.00        10\n",
      "        1840       0.12      0.10      0.11        10\n",
      "        1850       0.00      0.00      0.00        10\n",
      "        1860       0.05      0.10      0.06        10\n",
      "        1870       0.00      0.00      0.00        10\n",
      "        1880       0.29      0.50      0.37        10\n",
      "        1890       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.07       200\n",
      "   macro avg       0.05      0.07      0.05       200\n",
      "weighted avg       0.05      0.07      0.05       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "print(\"Loading model...\")\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "model.eval()\n",
    "test_set = HistoricalTextDataset(f'{test_data_path}', word_to_id, max_length=300)\n",
    "\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "for x, y in test_set:\n",
    "    with torch.no_grad():\n",
    "        logits = model([x])\n",
    "        predicted = torch.argmax(logits, dim=1).cpu().numpy()[0]\n",
    "        all_predictions.append(predicted)\n",
    "        all_labels.append(y)\n",
    "\n",
    "# Main evaluation metrics\n",
    "accuracy = accuracy_score(all_labels, all_predictions)\n",
    "decade_labels = [f\"{i}\" for i in range(1700, 1900, 10)]\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(all_labels, all_predictions)\n",
    "print(cm)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_predictions, target_names=decade_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f8acc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workbench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
